#!/usr/bin/env python3
"""
å„ãƒªãƒã‚¸ãƒˆãƒªãƒ•ã‚©ãƒ«ãƒ€ã«å€‹åˆ¥ã®æ—¥å ±ã®ã¿ã‚’ç”Ÿæˆã™ã‚‹ã‚·ãƒ³ãƒ—ãƒ«ã‚¹ã‚¯ãƒªãƒ—ãƒˆ
ãƒ‡ãƒãƒƒã‚°æƒ…å ±ã‚’å¤§å¹…ã«è¿½åŠ 
"""

import os
import json
import glob
from pathlib import Path
from datetime import datetime
import litellm

def find_todays_repos():
    """ä»Šæ—¥ã®ãƒªãƒã‚¸ãƒˆãƒªãƒ•ã‚©ãƒ«ãƒ€ã‚’æ¤œç´¢"""
    today = datetime.now().strftime('%Y-%m-%d')
    year = today.split('-')[0]
    
    print(f"ğŸ” æ¤œç´¢é–‹å§‹: {today}")
    print(f"ğŸ“… å¹´: {year}")
    
    # activities ãƒ‡ã‚£ãƒ¬ã‚¯ãƒˆãƒªã‹ã‚‰ä»Šæ—¥ã®ãƒ‡ãƒ¼ã‚¿ã‚’æ¢ã™
    activities_dir = Path('docs/docs/activities')
    print(f"ğŸ“ ãƒ™ãƒ¼ã‚¹ãƒ‡ã‚£ãƒ¬ã‚¯ãƒˆãƒª: {activities_dir}")
    print(f"ğŸ“ ãƒ‡ã‚£ãƒ¬ã‚¯ãƒˆãƒªå­˜åœ¨ç¢ºèª: {activities_dir.exists()}")
    
    repo_dirs = []
    
    # å¹´/é€±/æ—¥ä»˜ã®æ§‹é€ ã‚’æ¢ç´¢
    year_dirs = list(activities_dir.glob(year))
    print(f"ğŸ“‚ å¹´ãƒ‡ã‚£ãƒ¬ã‚¯ãƒˆãƒªæ•°: {len(year_dirs)}")
    
    for year_dir in year_dirs:
        print(f"ğŸ“‚ å¹´ãƒ‡ã‚£ãƒ¬ã‚¯ãƒˆãƒª: {year_dir}")
        week_dirs = list(year_dir.glob('week-*'))
        print(f"ğŸ“… é€±ãƒ‡ã‚£ãƒ¬ã‚¯ãƒˆãƒªæ•°: {len(week_dirs)}")
        
        for week_dir in week_dirs:
            print(f"ğŸ“… é€±ãƒ‡ã‚£ãƒ¬ã‚¯ãƒˆãƒª: {week_dir}")
            date_dir = week_dir / today
            print(f"ğŸ“… æ—¥ä»˜ãƒ‡ã‚£ãƒ¬ã‚¯ãƒˆãƒª: {date_dir}")
            print(f"ğŸ“… æ—¥ä»˜ãƒ‡ã‚£ãƒ¬ã‚¯ãƒˆãƒªå­˜åœ¨: {date_dir.exists()}")
            
            if date_dir.exists():
                repo_candidates = list(date_dir.iterdir())
                print(f"ğŸ” ãƒªãƒã‚¸ãƒˆãƒªå€™è£œæ•°: {len(repo_candidates)}")
                
                for repo_dir in repo_candidates:
                    print(f"ğŸ“¦ ãƒã‚§ãƒƒã‚¯ä¸­: {repo_dir}")
                    print(f"ğŸ“¦ ãƒ‡ã‚£ãƒ¬ã‚¯ãƒˆãƒª?: {repo_dir.is_dir()}")
                    
                    metadata_file = repo_dir / 'metadata.json'
                    print(f"ğŸ“‹ metadata.json: {metadata_file}")
                    print(f"ğŸ“‹ metadata.jsonå­˜åœ¨: {metadata_file.exists()}")
                    
                    if repo_dir.is_dir() and metadata_file.exists():
                        repo_dirs.append(repo_dir)
                        print(f"âœ… è¿½åŠ : {repo_dir}")
                    else:
                        print(f"âŒ ã‚¹ã‚­ãƒƒãƒ—: {repo_dir}")
    
    print(f"ğŸ“Š æœ€çµ‚çš„ã«è¦‹ã¤ã‹ã£ãŸãƒªãƒã‚¸ãƒˆãƒªæ•°: {len(repo_dirs)}")
    for repo_dir in repo_dirs:
        print(f"  ğŸ“¦ {repo_dir}")
    
    return today, repo_dirs

def load_repo_data(repo_dir):
    """ãƒªãƒã‚¸ãƒˆãƒªã®ãƒ‡ãƒ¼ã‚¿ã‚’èª­ã¿è¾¼ã¿"""
    print(f"\nğŸ“– ãƒ‡ãƒ¼ã‚¿èª­ã¿è¾¼ã¿é–‹å§‹: {repo_dir.name}")
    repo_data = {'name': repo_dir.name, 'path': repo_dir}
    
    # å„ãƒ•ã‚¡ã‚¤ãƒ«ã®å­˜åœ¨ç¢ºèªã¨èª­ã¿è¾¼ã¿
    files_to_check = [
        ('summary', 'daily_summary.md'),
        ('commits', 'daily_commits.md'),
        ('changes', 'daily_cumulative_diff.md'),
        ('stats', 'daily_diff_stats.md'),
        ('code_diff', 'daily_code_diff.md')
    ]
    
    for key, filename in files_to_check:
        file_path = repo_dir / filename
        print(f"  ğŸ“„ {filename}: å­˜åœ¨={file_path.exists()}")
        
        if file_path.exists():
            try:
                with open(file_path, 'r', encoding='utf-8') as f:
                    content = f.read()
                    if key == 'commits':
                        content = content[:3000]  # æœ€åˆã®3000æ–‡å­—
                    repo_data[key] = content
                    print(f"    âœ… èª­ã¿è¾¼ã¿æˆåŠŸ: {len(content)} æ–‡å­—")
            except Exception as e:
                print(f"    âŒ èª­ã¿è¾¼ã¿ã‚¨ãƒ©ãƒ¼: {e}")
        else:
            print(f"    âš ï¸ ãƒ•ã‚¡ã‚¤ãƒ«ãªã—")
    
    print(f"ğŸ“– èª­ã¿è¾¼ã¿å®Œäº†: {len(repo_data)-2} ãƒ•ã‚¡ã‚¤ãƒ«")  # name, pathé™¤ã
    return repo_data

def generate_repo_daily_report(repo_data, date):
    """å€‹åˆ¥ãƒªãƒã‚¸ãƒˆãƒªã®æ—¥å ±ã‚’ç”Ÿæˆ"""
    repo_name = repo_data['name']
    print(f"\nğŸ¤– AIæ—¥å ±ç”Ÿæˆé–‹å§‹: {repo_name}")
    
    # ãƒ—ãƒ­ãƒ³ãƒ—ãƒˆæ§‹ç¯‰
    prompt_parts = [f"ä»¥ä¸‹ã®{repo_name}ãƒªãƒã‚¸ãƒˆãƒªã®{date}ã®æ´»å‹•ãƒ‡ãƒ¼ã‚¿ã‹ã‚‰ã€æ—¥å ±ã‚’Markdownå½¢å¼ã§ä½œæˆã—ã¦ãã ã•ã„:\n"]
    
    if 'summary' in repo_data:
        prompt_parts.append(f"## ã‚µãƒãƒªãƒ¼:\n{repo_data['summary']}\n")
        print(f"  ğŸ“Š ã‚µãƒãƒªãƒ¼è¿½åŠ : {len(repo_data['summary'])} æ–‡å­—")
    
    if 'commits' in repo_data:
        prompt_parts.append(f"## ã‚³ãƒŸãƒƒãƒˆè©³ç´°:\n{repo_data['commits']}\n")
        print(f"  ğŸ’» ã‚³ãƒŸãƒƒãƒˆè¿½åŠ : {len(repo_data['commits'])} æ–‡å­—")
    
    if 'changes' in repo_data:
        prompt_parts.append(f"## ãƒ•ã‚¡ã‚¤ãƒ«å¤‰æ›´:\n{repo_data['changes']}\n")
        print(f"  ğŸ“ å¤‰æ›´è¿½åŠ : {len(repo_data['changes'])} æ–‡å­—")
    
    if 'stats' in repo_data:
        prompt_parts.append(f"## çµ±è¨ˆ:\n{repo_data['stats']}\n")
        print(f"  ğŸ“ˆ çµ±è¨ˆè¿½åŠ : {len(repo_data['stats'])} æ–‡å­—")
    
    prompt_parts.append("""
æ—¥å ±ä½œæˆè¦æ±‚:
- ã“ã®ãƒªãƒã‚¸ãƒˆãƒªã®ä»Šæ—¥ã®é–‹ç™ºæ´»å‹•ã‚’è¦ç´„
- ä¸»è¦ãªå¤‰æ›´ç‚¹ã¨æŠ€è¡“çš„ãƒã‚¤ãƒ³ãƒˆã‚’ãƒã‚¤ãƒ©ã‚¤ãƒˆ
- é–‹ç™ºã®é€²æ—çŠ¶æ³ã‚’è©•ä¾¡
- æ³¨ç›®ã™ã¹ãæ”¹å–„ã‚„è¿½åŠ æ©Ÿèƒ½ãŒã‚ã‚Œã°è¨€åŠ
- æ˜æ—¥ä»¥é™ã®é–‹ç™ºã¸ã®ææ¡ˆãŒã‚ã‚Œã°è¨˜è¼‰
- æ—¥æœ¬èªã§èª­ã¿ã‚„ã™ãã€ç°¡æ½”ã«è¨˜è¿°
- çµµæ–‡å­—ã‚’åŠ¹æœçš„ã«ä½¿ç”¨""")
    
    prompt = "\n".join(prompt_parts)
    print(f"ğŸ¤– ãƒ—ãƒ­ãƒ³ãƒ—ãƒˆé•·: {len(prompt)} æ–‡å­—")
    print(f"ğŸ¤– ä½¿ç”¨ãƒ¢ãƒ‡ãƒ«: gemini/gemini-2.5-pro")
    
    try:
        print("ğŸ¤– APIå‘¼ã³å‡ºã—é–‹å§‹...")
        response = litellm.completion(
            model="gemini/gemini-2.5-pro",  # æ­£ã—ã„ãƒ¢ãƒ‡ãƒ«åã«ä¿®æ­£
            messages=[{"role": "user", "content": prompt}],
            temperature=0.7,
        )
        
        content = response.choices[0].message.content
        print(f"âœ… AIå¿œç­”å—ä¿¡: {len(content)} æ–‡å­—")
        print(f"ğŸ“ AIå¿œç­”ãƒ—ãƒ¬ãƒ“ãƒ¥ãƒ¼: {content[:100]}...")
        
        return content
        
    except Exception as e:
        print(f"âŒ AIç”Ÿæˆã‚¨ãƒ©ãƒ¼ ({repo_name}): {e}")
        print(f"ğŸ” ã‚¨ãƒ©ãƒ¼è©³ç´°: {type(e).__name__}")
        
        # ãƒ•ã‚©ãƒ¼ãƒ«ãƒãƒƒã‚¯æ—¥å ±
        fallback_content = f"""# ğŸ“… {repo_name} - æ—¥å ± ({date})

## ğŸ“Š åŸºæœ¬æƒ…å ±
- ãƒªãƒã‚¸ãƒˆãƒª: {repo_name}
- æ—¥ä»˜: {date}
- ç”Ÿæˆæ™‚åˆ»: {datetime.now().strftime('%Y-%m-%d %H:%M:%S')}

## âš ï¸ æ³¨æ„
AI ã«ã‚ˆã‚‹æ—¥å ±ç”Ÿæˆã«å¤±æ•—ã—ã¾ã—ãŸã€‚æ—¢å­˜ã®ã‚µãƒãƒªãƒ¼ãƒ•ã‚¡ã‚¤ãƒ«ã‚’ã”ç¢ºèªãã ã•ã„ã€‚

### åˆ©ç”¨å¯èƒ½ãªãƒ‡ãƒ¼ã‚¿
"""
        
        for key in ['summary', 'commits', 'changes', 'stats']:
            if key in repo_data:
                fallback_content += f"- {key}: âœ…\n"
            else:
                fallback_content += f"- {key}: âŒ\n"
        
        fallback_content += "\n---\n*æ‰‹å‹•ã§ã®æ—¥å ±ä½œæˆã‚’ãŠé¡˜ã„ã—ã¾ã™*"
        
        return fallback_content

def save_repo_daily_report(repo_data, daily_report, date):
    """ãƒªãƒã‚¸ãƒˆãƒªãƒ•ã‚©ãƒ«ãƒ€ã«æ—¥å ±ã‚’ä¿å­˜"""
    repo_dir = repo_data['path']
    report_file = repo_dir / 'ai_daily_report.md'
    
    print(f"\nğŸ’¾ ãƒ•ã‚¡ã‚¤ãƒ«ä¿å­˜é–‹å§‹: {report_file}")
    
    # ãƒ•ãƒ­ãƒ³ãƒˆãƒã‚¿ãƒ¼ä½œæˆï¼ˆãƒ‡ãƒãƒƒã‚°æƒ…å ±ä»˜ãï¼‰
    frontmatter = f"""---
title: "{repo_data['name']} - AIæ—¥å ±"
date: "{date}"
sidebar_position: 1
description: "AIç”Ÿæˆã«ã‚ˆã‚‹{repo_data['name']}ã®é–‹ç™ºæ—¥å ±"
tags: ["daily-report", "ai-generated", "{repo_data['name']}", "{date}"]
---

"""
    
    print(f"ğŸ“ ãƒ•ãƒ­ãƒ³ãƒˆãƒã‚¿ãƒ¼:")
    print(frontmatter)
    
    # å®Œå…¨ãªã‚³ãƒ³ãƒ†ãƒ³ãƒ„
    full_content = frontmatter + daily_report
    
    print(f"ğŸ“ ç·ã‚³ãƒ³ãƒ†ãƒ³ãƒ„é•·: {len(full_content)} æ–‡å­—")
    
    try:
        with open(report_file, 'w', encoding='utf-8') as f:
            f.write(full_content)
        
        print(f"âœ… ãƒ•ã‚¡ã‚¤ãƒ«ä¿å­˜æˆåŠŸ: {report_file}")
        
        # ä¿å­˜å¾Œã®ç¢ºèª
        if report_file.exists():
            file_size = report_file.stat().st_size
            print(f"ğŸ“Š ä¿å­˜ãƒ•ã‚¡ã‚¤ãƒ«ã‚µã‚¤ã‚º: {file_size} bytes")
        else:
            print(f"âŒ ãƒ•ã‚¡ã‚¤ãƒ«ä¿å­˜ç¢ºèªå¤±æ•—")
            
    except Exception as e:
        print(f"âŒ ãƒ•ã‚¡ã‚¤ãƒ«ä¿å­˜ã‚¨ãƒ©ãƒ¼: {e}")

def main():
    print("ğŸš€ Gemini 2.5 Pro ã§å€‹åˆ¥ãƒªãƒã‚¸ãƒˆãƒªæ—¥å ±ç”Ÿæˆé–‹å§‹")
    print(f"â° å®Ÿè¡Œæ™‚åˆ»: {datetime.now().isoformat()}")
    
    # ç’°å¢ƒå¤‰æ•°ç¢ºèª
    api_key = os.getenv('GOOGLE_API_KEY')
    if api_key:
        print(f"ğŸ”‘ GOOGLE_API_KEY: è¨­å®šæ¸ˆã¿ (é•·ã•: {len(api_key)})")
    else:
        print("âŒ GOOGLE_API_KEY: æœªè¨­å®š")
        return
    
    # ãƒ‡ãƒ¼ã‚¿åé›†
    print("\n" + "="*50)
    print("ğŸ“Š ãƒ‡ãƒ¼ã‚¿åé›†ãƒ•ã‚§ãƒ¼ã‚º")
    print("="*50)
    
    date, repo_dirs = find_todays_repos()
    print(f"\nğŸ“Š çµæœ: {date} - {len(repo_dirs)}å€‹ã®ãƒªãƒã‚¸ãƒˆãƒª")
    
    if not repo_dirs:
        print("ğŸ“ æœ¬æ—¥ã®æ´»å‹•ãªã— - å‡¦ç†çµ‚äº†")
        return
    
    # å„ãƒªãƒã‚¸ãƒˆãƒªã®æ—¥å ±ç”Ÿæˆ
    print("\n" + "="*50)
    print("ğŸ¤– æ—¥å ±ç”Ÿæˆãƒ•ã‚§ãƒ¼ã‚º")
    print("="*50)
    
    for i, repo_dir in enumerate(repo_dirs, 1):
        print(f"\n--- {i}/{len(repo_dirs)}: {repo_dir.name} ---")
        
        # ãƒ‡ãƒ¼ã‚¿èª­ã¿è¾¼ã¿
        repo_data = load_repo_data(repo_dir)
        
        # æ—¥å ±ç”Ÿæˆ
        daily_report = generate_repo_daily_report(repo_data, date)
        
        # ä¿å­˜
        save_repo_daily_report(repo_data, daily_report, date)
    
    print("\n" + "="*50)
    print("âœ… å…¨ãƒªãƒã‚¸ãƒˆãƒªã®æ—¥å ±ç”Ÿæˆå®Œäº†")
    print("="*50)

if __name__ == "__main__":
    main()
