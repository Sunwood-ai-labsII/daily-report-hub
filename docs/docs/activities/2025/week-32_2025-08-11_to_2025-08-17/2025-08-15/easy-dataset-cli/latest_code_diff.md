# ğŸ”„ Latest Code Changes

```diff
diff --git a/README.md b/README.md
index 0946c9a..17cd67d 100644
--- a/README.md
+++ b/README.md
@@ -77,6 +77,22 @@ uv run easy-dataset generate .\example\input\documents\sample_document.txt \
   --export-alpaca
 \```
 
+#### æ€è€ƒãƒ•ãƒ­ãƒ¼ä»˜ãQ&Aã®ç”Ÿæˆ
+\```bash
+# æ€è€ƒãƒ•ãƒ­ãƒ¼ã‚’å«ã‚€Q&Aãƒšã‚¢ã‚’ç”Ÿæˆ
+uv run easy-dataset generate .\example\input\documents\sample_document.txt \
+  --ga-file .\example\output\sample_document\ga\ga_definitions.xml \
+  --output-dir .\example\output\sample_document\ \
+  --use-thinking
+
+# æ€è€ƒãƒ•ãƒ­ãƒ¼ã¨å…¨æ–‡ã‚³ãƒ³ãƒ†ã‚­ã‚¹ãƒˆã‚’ä½µç”¨ã—ã¦ç”Ÿæˆ
+uv run easy-dataset generate .\example\input\documents\sample_document.txt \
+  --ga-file .\example\output\sample_document\ga\ga_definitions.xml \
+  --output-dir .\example\output\sample_document\ \
+  --use-thinking \
+  --use-fulltext
+\```
+
 #### Hugging Face Hubã¸ã®ç›´æ¥ã‚¢ãƒƒãƒ—ãƒ­ãƒ¼ãƒ‰
 \```bash
 # ç’°å¢ƒå¤‰æ•°ã§ãƒˆãƒ¼ã‚¯ãƒ³ã‚’è¨­å®š
@@ -130,6 +146,8 @@ Options:
   -m, --model TEXT         Q&Aãƒšã‚¢ã®ç”Ÿæˆã«ä½¿ç”¨ã™ã‚‹LLMãƒ¢ãƒ‡ãƒ« [default: openrouter/openai/gpt-4o]
   --chunk-size INTEGER     ãƒ†ã‚­ã‚¹ãƒˆãƒãƒ£ãƒ³ã‚¯ã®æœ€å¤§ã‚µã‚¤ã‚º [default: 2000]
   --chunk-overlap INTEGER  ãƒãƒ£ãƒ³ã‚¯é–“ã®ã‚ªãƒ¼ãƒãƒ¼ãƒ©ãƒƒãƒ—ã‚µã‚¤ã‚º [default: 200]
+  -f, --use-fulltext       å…¨æ–‡ã‚’ã‚³ãƒ³ãƒ†ã‚­ã‚¹ãƒˆã¨ã—ã¦å«ã‚ã¦QAç”Ÿæˆã‚’è¡Œã„ã¾ã™ã€‚ã‚ˆã‚Šæ–‡è„ˆã‚’ç†è§£ã—ãŸQAãŒç”Ÿæˆã•ã‚Œã¾ã™ãŒã€å‡¦ç†æ™‚é–“ã¨ã‚³ã‚¹ãƒˆãŒå¢—åŠ ã—ã¾ã™ã€‚
+  -T, --use-thinking       å„Q&Aãƒšã‚¢ã«æ€è€ƒãƒ—ãƒ­ã‚»ã‚¹ã‚’è¿½åŠ ã—ã¦ç”Ÿæˆã—ã¾ã™ã€‚ã‚ˆã‚Šæ·±ã„ç†è§£ã¨èª¬æ˜ãŒå¯èƒ½ã«ãªã‚Šã¾ã™ãŒã€å‡¦ç†æ™‚é–“ã¨ã‚³ã‚¹ãƒˆãŒå¢—åŠ ã—ã¾ã™ã€‚
   -h, --help               Show this message and exit
 \```
 
diff --git a/easy_dataset_cli/alpaca_converter.py b/easy_dataset_cli/alpaca_converter.py
index 0a148ea..3e31713 100644
--- a/easy_dataset_cli/alpaca_converter.py
+++ b/easy_dataset_cli/alpaca_converter.py
@@ -31,8 +31,7 @@ def xml_to_alpaca_format(xml_file_path: Path) -> List[Dict[str, str]]:
                 audience = audience_elem.text or ""
                 question = question_elem.text or ""
                 answer = answer_elem.text or ""
-                
-                # ã‚¢ãƒ«ãƒ‘ã‚«å½¢å¼ã«å¤‰æ›
+                # Answerã‚¿ã‚°ã®å†…å®¹ã‚’ãã®ã¾ã¾outputã«å…¥ã‚Œã‚‹ï¼ˆ<think>...</think>å«ã‚€ï¼‰
                 alpaca_entry = {
                     "instruction": question,
                     "input": "",  # ã‚¢ãƒ«ãƒ‘ã‚«å½¢å¼ã§ã¯é€šå¸¸ç©ºæ–‡å­—
diff --git a/easy_dataset_cli/core.py b/easy_dataset_cli/core.py
index 056452b..b308563 100644
--- a/easy_dataset_cli/core.py
+++ b/easy_dataset_cli/core.py
@@ -9,10 +9,11 @@ from .ga_parser import (
 from .qa_generator import (
     generate_qa_for_chunk_with_ga,
     generate_qa_for_chunk_with_ga_and_fulltext,
+    generate_qa_for_chunk_with_ga_and_thinking,
     generate_ga_definitions
 )
 from .text_splitter import split_text
-from .xml_utils import convert_to_xml_by_genre
+from .xml_utils import convert_to_xml_by_genre, load_existing_xml_file, aggregate_logs_xml_to_qa
 from .file_utils import (
     create_output_directories,
     save_ga_definitions_by_genre,
@@ -33,6 +34,7 @@ __all__ = [
     # Q&Aç”Ÿæˆé–¢é€£
     'generate_qa_for_chunk_with_ga',
     'generate_qa_for_chunk_with_ga_and_fulltext',
+    'generate_qa_for_chunk_with_ga_and_thinking',
     'generate_ga_definitions',
     
     # ãƒ†ã‚­ã‚¹ãƒˆåˆ†å‰²
@@ -40,6 +42,8 @@ __all__ = [
     
     # XMLå‡¦ç†
     'convert_to_xml_by_genre',
+    'load_existing_xml_file',
+    'aggregate_logs_xml_to_qa',
     
     # ãƒ•ã‚¡ã‚¤ãƒ«æ“ä½œ
     'create_output_directories',
diff --git a/easy_dataset_cli/ga_parser.py b/easy_dataset_cli/ga_parser.py
index fb9aa16..cdeb17d 100644
--- a/easy_dataset_cli/ga_parser.py
+++ b/easy_dataset_cli/ga_parser.py
@@ -172,7 +172,7 @@ def parse_ga_definitions_from_xml(xml_content: str) -> List[Dict[str, Dict[str,
         console.print(f"[dim]å•é¡Œã®ã‚ã‚‹XML: {xml_content[xml_start:xml_start+200] if xml_start != -1 else xml_content[:200]}...[/dim]")
 
         # XMLã‚¨ãƒ©ãƒ¼ã®å ´åˆã€æ‰‹å‹•ã§ãƒ†ã‚­ã‚¹ãƒˆè§£æã‚’è©¦è¡Œ
-        console.print("[yellow]æ‰‹å‹•è§£æã‚’è©¦è¡Œä¸­...[/yellow]")
+        console.print("[yellow]è‡ªå‹•è§£æã‚’è©¦è¡Œä¸­...[/yellow]")
         from .xml_utils import parse_ga_from_text_fallback
         pairs = parse_ga_from_text_fallback(xml_content)
 
diff --git a/easy_dataset_cli/main.py b/easy_dataset_cli/main.py
index 6f62532..9285adf 100644
--- a/easy_dataset_cli/main.py
+++ b/easy_dataset_cli/main.py
@@ -13,6 +13,7 @@ from .core import (
     parse_ga_file,
     generate_qa_for_chunk_with_ga,
     generate_qa_for_chunk_with_ga_and_fulltext,
+    generate_qa_for_chunk_with_ga_and_thinking,
     convert_to_xml_by_genre,
     generate_ga_definitions,
     parse_ga_definitions_from_xml,
@@ -143,6 +144,14 @@ def generate(
         "--use-fulltext", "-f",
         help="å…¨æ–‡ã‚’ã‚³ãƒ³ãƒ†ã‚­ã‚¹ãƒˆã¨ã—ã¦å«ã‚ã¦QAç”Ÿæˆã‚’è¡Œã„ã¾ã™ã€‚ã‚ˆã‚Šæ–‡è„ˆã‚’ç†è§£ã—ãŸQAãŒç”Ÿæˆã•ã‚Œã¾ã™ãŒã€å‡¦ç†æ™‚é–“ã¨ã‚³ã‚¹ãƒˆãŒå¢—åŠ ã—ã¾ã™ã€‚"
     )] = False,
+    use_thinking: Annotated[bool, typer.Option(
+        "--use-thinking", "-T",
+        help="å„Q&Aãƒšã‚¢ã«æ€è€ƒãƒ—ãƒ­ã‚»ã‚¹ã‚’è¿½åŠ ã—ã¦ç”Ÿæˆã—ã¾ã™ã€‚ã‚ˆã‚Šæ·±ã„ç†è§£ã¨èª¬æ˜ãŒå¯èƒ½ã«ãªã‚Šã¾ã™ãŒã€å‡¦ç†æ™‚é–“ã¨ã‚³ã‚¹ãƒˆãŒå¢—åŠ ã—ã¾ã™ã€‚"
+    )] = False,
+    append_mode: Annotated[bool, typer.Option(
+        "--append", "-A",
+        help="æ—¢å­˜ã®XMLãƒ•ã‚¡ã‚¤ãƒ«ã«æ–°ã—ã„Q&Aã‚’è¿½åŠ ã—ã¾ã™ã€‚æŒ‡å®šã—ãªã„å ´åˆã¯ä¸Šæ›¸ãã—ã¾ã™ã€‚"
+    )] = False,
     export_alpaca: Annotated[bool, typer.Option(
         "--export-alpaca", "-a",
         help="ç”Ÿæˆã•ã‚ŒãŸQ&Aãƒšã‚¢ã‚’Alpacaå½¢å¼ã®JSONãƒ•ã‚¡ã‚¤ãƒ«ã¨ã—ã¦å‡ºåŠ›ã—ã¾ã™ã€‚"
@@ -200,12 +209,25 @@ def generate(
             console.print("[yellow]âš  å…¨æ–‡ã‚³ãƒ³ãƒ†ã‚­ã‚¹ãƒˆãƒ¢ãƒ¼ãƒ‰ãŒæœ‰åŠ¹ã§ã™ã€‚å‡¦ç†æ™‚é–“ã¨ã‚³ã‚¹ãƒˆãŒå¢—åŠ ã™ã‚‹å¯èƒ½æ€§ãŒã‚ã‚Šã¾ã™ã€‚[/yellow]")
             console.print(f"[dim]å…¨æ–‡é•·: {len(text)} æ–‡å­—[/dim]")
 
+        # æ€è€ƒãƒ•ãƒ­ãƒ¼ä½¿ç”¨ã®å ´åˆã¯è­¦å‘Šã‚’è¡¨ç¤º
+        if use_thinking:
+            console.print("[yellow]âš  æ€è€ƒãƒ•ãƒ­ãƒ¼ãƒ¢ãƒ¼ãƒ‰ãŒæœ‰åŠ¹ã§ã™ã€‚å„Q&Aã«æ€è€ƒãƒ—ãƒ­ã‚»ã‚¹ãŒè¿½åŠ ã•ã‚Œã¾ã™ã€‚[/yellow]")
+
         with Progress(console=console) as progress:
             task = progress.add_task("[green]Q&Aãƒšã‚¢ã‚’ç”Ÿæˆä¸­...", total=total_tasks)
 
             for chunk in chunks:
                 for ga_pair in ga_pairs:
-                    if use_fulltext:
+                    if use_thinking:
+                        qa_pairs = generate_qa_for_chunk_with_ga_and_thinking(
+                            chunk=chunk,
+                            full_text=text if use_fulltext else "",
+                            model=model,
+                            ga_pair=ga_pair,
+                            logs_dir=dirs["logs"] if dirs else None,
+                            num_qa_pairs=num_qa_pairs
+                        )
+                    elif use_fulltext:
                         qa_pairs = generate_qa_for_chunk_with_ga_and_fulltext(
                             chunk=chunk,
                             full_text=text,
@@ -222,12 +244,13 @@ def generate(
                         )
 
                     for pair in qa_pairs:
-                        all_qa_pairs_with_ga.append({
+                        qa_entry = {
                             "genre": ga_pair['genre']['title'],
                             "audience": ga_pair['audience']['title'],
                             "question": pair['question'],
-                            "answer": pair['answer'],
-                        })
+                            "answer": pair['answer'],  # <think>...</think>å›ç­”...å½¢å¼ãŒãã®ã¾ã¾å…¥ã‚‹
+                        }
+                        all_qa_pairs_with_ga.append(qa_entry)
 
                     progress.update(
                         task, advance=1,
@@ -239,7 +262,7 @@ def generate(
             "å€‹ã®Q&Aãƒšã‚¢ã‚’ç”Ÿæˆã—ã¾ã—ãŸã€‚"
         )
 
-        xml_outputs_by_genre = convert_to_xml_by_genre(all_qa_pairs_with_ga)
+        xml_outputs_by_genre = convert_to_xml_by_genre(all_qa_pairs_with_ga, dirs["qa"] if dirs else None, append_mode)
 
         if dirs:
             console.print(f"XMLãƒ•ã‚¡ã‚¤ãƒ«ã‚’ [cyan]{dirs['qa']}[/cyan] ã«ä¿å­˜ã—ã¦ã„ã¾ã™...")
@@ -286,7 +309,12 @@ def generate(
                 console.print(xml_content, overflow="fold")
     
     except Exception as e:
-        console.print(f"[bold red]ã‚¨ãƒ©ãƒ¼ãŒç™ºç”Ÿã—ã¾ã—ãŸ:[/bold red] {e}")
+        console.print(f"[bold red]ã‚¨ãƒ©ãƒ¼ãŒç™ºç”Ÿã—ã¾ã—ãŸ:[/bold red]")
+        console.print(f"[bold red]ã‚¨ãƒ©ãƒ¼ã‚¿ã‚¤ãƒ—:[/bold red] {type(e).__name__}")
+        console.print(f"[bold red]ã‚¨ãƒ©ãƒ¼ãƒ¡ãƒƒã‚»ãƒ¼ã‚¸:[/bold red] {str(e)}")
+        console.print(f"[bold red]ãƒˆãƒ¬ãƒ¼ã‚¹ãƒãƒƒã‚¯:[/bold red]")
+        import traceback
+        console.print(traceback.format_exc())
         raise typer.Exit(code=1)
 
 
@@ -365,5 +393,36 @@ def convert_to_alpaca(
         raise typer.Exit(code=1)
 
 
+@app.command()
+def aggregate_logs(
+    output_dir: Annotated[Path, typer.Argument(
+        exists=True, dir_okay=True, readable=True,
+        help="logsãƒ•ã‚©ãƒ«ãƒ€ãŒå«ã¾ã‚Œã‚‹å‡ºåŠ›ãƒ‡ã‚£ãƒ¬ã‚¯ãƒˆãƒªã¸ã®ãƒ‘ã‚¹ã€‚"
+    )]
+):
+    """logsãƒ•ã‚©ãƒ«ãƒ€å†…ã®ã‚¿ã‚¤ãƒ ã‚¹ã‚¿ãƒ³ãƒ—ä»˜ãXMLãƒ•ã‚¡ã‚¤ãƒ«ã‚’é›†ç´„ã—ã¦qaãƒ•ã‚©ãƒ«ãƒ€ã®XMLã‚’ç”Ÿæˆã—ã¾ã™ã€‚"""
+    
+    try:
+        logs_dir = output_dir / "logs"
+        qa_dir = output_dir / "qa"
+        
+        if not logs_dir.exists():
+            console.print(f"[bold red]logsãƒ•ã‚©ãƒ«ãƒ€ãŒè¦‹ã¤ã‹ã‚Šã¾ã›ã‚“: {logs_dir}[/bold red]")
+            raise typer.Exit(code=1)
+        
+        console.print(f"logsãƒ•ã‚©ãƒ«ãƒ€: [cyan]{logs_dir}[/cyan]")
+        console.print(f"å‡ºåŠ›å…ˆqaãƒ•ã‚©ãƒ«ãƒ€: [cyan]{qa_dir}[/cyan]")
+        
+        # XMLãƒ•ã‚¡ã‚¤ãƒ«ã‚’é›†ç´„ã—ã¦qaãƒ•ã‚©ãƒ«ãƒ€ã«ç”Ÿæˆ
+        from easy_dataset_cli.core import aggregate_logs_xml_to_qa
+        aggregate_logs_xml_to_qa(logs_dir, qa_dir)
+        
+        console.print(f"\n[bold green]âœ“[/bold green] é›†ç´„ãŒå®Œäº†ã—ã¾ã—ãŸï¼")
+        
+    except Exception as e:
+        console.print(f"[bold red]ã‚¨ãƒ©ãƒ¼ãŒç™ºç”Ÿã—ã¾ã—ãŸ:[/bold red] {e}")
+        raise typer.Exit(code=1)
+
+
 if __name__ == "__main__":
     app()
diff --git a/easy_dataset_cli/prompts.py b/easy_dataset_cli/prompts.py
index 24ba9f9..c2b00b8 100644
--- a/easy_dataset_cli/prompts.py
+++ b/easy_dataset_cli/prompts.py
@@ -28,3 +28,8 @@ def get_qa_generation_with_fulltext_prompt() -> str:
 def get_ga_definition_generation_prompt() -> str:
     """GAå®šç¾©ç”Ÿæˆãƒ—ãƒ­ãƒ³ãƒ—ãƒˆã‚’å–å¾—"""
     return load_prompt_template("ga_definition_generation")
+
+
+def get_qa_generation_with_thinking_prompt() -> str:
+    """æ€è€ƒãƒ•ãƒ­ãƒ¼å¯¾å¿œQ&Aç”Ÿæˆãƒ—ãƒ­ãƒ³ãƒ—ãƒˆã‚’å–å¾—"""
+    return load_prompt_template("qa_generation_with_thinking")
diff --git a/easy_dataset_cli/prompts/ga_definition_generation.md b/easy_dataset_cli/prompts/ga_definition_generation.md
index 757afcd..17c05a4 100644
--- a/easy_dataset_cli/prompts/ga_definition_generation.md
+++ b/easy_dataset_cli/prompts/ga_definition_generation.md
@@ -7,7 +7,7 @@
 2. ã“ã®æ–‡ç« ã‹ã‚‰è³ªå•ã¨å›ç­”ã®ãƒšã‚¢ã‚’ç”Ÿæˆã™ã‚‹éš›ã«æœ€é©ã¨ãªã‚‹{num_ga_pairs}å€‹ã®Genre-Audienceãƒšã‚¢ã‚’ææ¡ˆã—ã¦ãã ã•ã„ã€‚
 3. å„Genreã¯ç•°ãªã‚‹æ–‡ä½“ãƒ»å½¢å¼ï¼ˆå­¦è¡“è«–æ–‡ã€æŠ€è¡“ãƒ–ãƒ­ã‚°ã€æ•™ç§‘æ›¸ã€FAQã€å¯¾è©±å½¢å¼ãªã©ï¼‰ã‚’è¡¨ç¾ã—ã¦ãã ã•ã„ã€‚
 4. å„Audienceã¯ç•°ãªã‚‹çŸ¥è­˜ãƒ¬ãƒ™ãƒ«ãƒ»ç«‹å ´ï¼ˆåˆå¿ƒè€…ã€å­¦ç”Ÿã€å°‚é–€å®¶ã€å®Ÿå‹™è€…ãªã©ï¼‰ã‚’è¡¨ç¾ã—ã¦ãã ã•ã„ã€‚
-5. æ–‡ç« ã®å†…å®¹ã«é©ã—ãŸãƒšã‚¢ã‚’é¸æŠã—ã€å¤šæ§˜æ€§ã‚’ç¢ºä¿ã—ã¦ãã ã•ã„ã€‚
+5. æ–‡ç« ã®å†…å®¹ã«é©ã—ãŸãƒšã‚¢ã‚’é¸æŠã—ã€å¤šæ§˜æ€§ãƒ»å¤šè§’æ€§ã‚’ç¢ºä¿ã—ã¦ãã ã•ã„ã€‚
 
 ## æ–‡ç« :
 ---
diff --git a/easy_dataset_cli/prompts/qa_generation_with_thinking.md b/easy_dataset_cli/prompts/qa_generation_with_thinking.md
new file mode 100644
index 0000000..2bb04fe
--- /dev/null
+++ b/easy_dataset_cli/prompts/qa_generation_with_thinking.md
@@ -0,0 +1,53 @@
+# å½¹å‰²: Q&Aãƒšã‚¢ç”Ÿæˆã®å°‚é–€å®¶ï¼ˆæ€è€ƒãƒ•ãƒ­ãƒ¼å¯¾å¿œç‰ˆï¼‰
+
+ã‚ãªãŸã¯ã€ä¸ãˆã‚‰ã‚ŒãŸæ–‡ç« ã‹ã‚‰é«˜å“è³ªãªè³ªå•ã¨å›ç­”ã®ãƒšã‚¢ã‚’ä½œæˆã™ã‚‹å°‚é–€å®¶ã§ã™ã€‚ç‰¹ã«ã€æŒ‡å®šã•ã‚ŒãŸã€Œä½“è£ã€ã¨ã€Œèª­è€…ã€ã«åˆã‚ã›ã¦ã‚¹ã‚¿ã‚¤ãƒ«ã‚’èª¿æ•´ã™ã‚‹èƒ½åŠ›ã«é•·ã‘ã¦ã„ã¾ã™ã€‚ã¾ãŸã€æ€è€ƒãƒ—ãƒ­ã‚»ã‚¹ã‚’æ˜ç¤ºçš„ã«è¨˜è¿°ã™ã‚‹èƒ½åŠ›ã«ã‚‚å„ªã‚Œã¦ã„ã¾ã™ã€‚
+
+## æŒ‡ç¤º:
+1. ä¸ãˆã‚‰ã‚ŒãŸã€Œå…¨æ–‡ã€ã¨ã€Œãƒãƒ£ãƒ³ã‚¯ã€ã‚’æ³¨æ„æ·±ãèª­ã‚“ã§ãã ã•ã„ã€‚
+2. æŒ‡å®šã•ã‚ŒãŸã€Œç›®æ¨™ã¨ã™ã‚‹ä½“è£ã€ã¨ã€Œç›®æ¨™ã¨ã™ã‚‹èª­è€…ã€ã®å½¹å‰²ã«ãªã‚Šãã£ã¦ãã ã•ã„ã€‚
+3. **ãƒãƒ£ãƒ³ã‚¯**ã®å†…å®¹ã‚’ä¸­å¿ƒã¨ã—ã¤ã¤ã€**å…¨æ–‡**ã®æ–‡è„ˆã‚’ç†è§£ã—ãŸä¸Šã§ã€{num_qa_pairs}å€‹ã®ãƒ¦ãƒ‹ãƒ¼ã‚¯ã§æ´å¯Ÿã«å¯Œã‚“ã Q&Aãƒšã‚¢ã‚’ç”Ÿæˆã—ã¦ãã ã•ã„ã€‚
+4. è³ªå•ã®ã‚¹ã‚¿ã‚¤ãƒ«ã¨è¤‡é›‘ã•ã¯ã€ã€Œç›®æ¨™ã¨ã™ã‚‹èª­è€…ã€ã®è¦–ç‚¹ã«åˆã‚ã›ã¦ãã ã•ã„ã€‚
+5. å›ç­”ã®ã‚¹ã‚¿ã‚¤ãƒ«ã€ãƒˆãƒ¼ãƒ³ã€è©³ç´°ã•ã¯ã€ã€Œç›®æ¨™ã¨ã™ã‚‹ä½“è£ã€ã«åˆã‚ã›ã¦ãã ã•ã„ã€‚
+6. **é‡è¦**: è³ªå•ã¨å›ç­”ã¯ä¸»ã«ã€Œãƒãƒ£ãƒ³ã‚¯ã€ã®å†…å®¹ã«åŸºã¥ã„ã¦ä½œæˆã—ã€ã€Œå…¨æ–‡ã€ã¯æ–‡è„ˆç†è§£ã®ãŸã‚ã®è£œåŠ©æƒ…å ±ã¨ã—ã¦æ´»ç”¨ã—ã¦ãã ã•ã„ã€‚
+7. å„Q&Aãƒšã‚¢ã«ã¯ã€æ€è€ƒãƒ—ãƒ­ã‚»ã‚¹ã‚’æ˜ç¤ºçš„ã«è¨˜è¿°ã—ã¦ãã ã•ã„ã€‚
+
+## ç›®æ¨™ã¨ã™ã‚‹ä½“è£:
+{genre_title}
+{genre_description}
+
+## ç›®æ¨™ã¨ã™ã‚‹èª­è€…:
+{audience_title}
+{audience_description}
+
+## å…¨æ–‡ï¼ˆæ–‡è„ˆç†è§£ç”¨ï¼‰:
+---
+{full_text}
+---
+
+## ãƒãƒ£ãƒ³ã‚¯ï¼ˆQAç”Ÿæˆå¯¾è±¡ï¼‰:
+---
+{chunk}
+---
+
+## å‡ºåŠ›å½¢å¼:
+**å¿…ãš**ã€ãƒ«ãƒ¼ãƒˆè¦ç´ ãŒ `<QAPairs>` ã§ã‚ã‚‹å˜ä¸€ã®æœ‰åŠ¹ãªXMLã¨ã—ã¦å¿œç­”ã—ã¦ãã ã•ã„ã€‚XMLä»¥å¤–ã®èª¬æ˜æ–‡ã¯ä¸€åˆ‡å«ã‚ãªã„ã§ãã ã•ã„ã€‚
+å„Q&Aãƒšã‚¢ã¯ `<Pair>` ã‚¿ã‚°ã§å›²ã¿ã€ãã®ä¸­ã« `<Question>` ã¨ `<Answer>` ã‚¿ã‚°ã‚’å«ã‚ã¦ãã ã•ã„ã€‚
+
+**é‡è¦**: å›ç­”ã¯å¿…ãš`<Answer><think>æ€è€ƒãƒ•ãƒ­ãƒ¼...</think>å›ç­”...</Answer>`ã®ã‚ˆã†ã«ã€æ€è€ƒãƒ•ãƒ­ãƒ¼ã‚’`<think>`ã‚¿ã‚°ã§å›²ã¿ã€å›ç­”æœ¬æ–‡ã®ç›´å‰ã«å«ã‚ã¦ãã ã•ã„ã€‚
+å›ç­”æ–‡ã«æ”¹è¡Œã‚’å«ã‚ãšã€ä¸€è¡Œã§è¨˜è¿°ã—ã¦ãã ã•ã„ã€‚
+
+## å‡ºåŠ›ä¾‹:
+\```xml
+<QAPairs>
+<Pair>
+<Question>ãƒŸãƒˆã‚³ãƒ³ãƒ‰ãƒªã‚¢ã®ä¸»ãªæ©Ÿèƒ½ã¯ä½•ã§ã™ã‹ï¼Ÿ</Question>
+<Answer><think>ãƒŸãƒˆã‚³ãƒ³ãƒ‰ãƒªã‚¢ã¯ç´°èƒã®ã€Œç™ºé›»æ‰€ã€ã¨ã—ã¦çŸ¥ã‚‰ã‚Œã¦ãŠã‚Šã€ç´°èƒå‘¼å¸ã‚’é€šã˜ã¦æ „é¤Šç´ ã‹ã‚‰ã‚¨ãƒãƒ«ã‚®ãƒ¼ã‚’ç”£ç”Ÿã™ã‚‹ã€‚ãã®ä¸»ãªç”£ç‰©ãŒATPã§ã‚ã‚Šã€ç´°èƒã®ã‚ã‚‰ã‚†ã‚‹ç”Ÿå‘½æ´»å‹•ã®ã‚¨ãƒãƒ«ã‚®ãƒ¼æºã¨ãªã‚‹ã€‚</think>ãƒŸãƒˆã‚³ãƒ³ãƒ‰ãƒªã‚¢ã®ä¸»ãªæ©Ÿèƒ½ã¯ã€ç´°èƒã®ã‚¨ãƒãƒ«ã‚®ãƒ¼é€šè²¨ã§ã‚ã‚‹ã‚¢ãƒ‡ãƒã‚·ãƒ³ä¸‰ãƒªãƒ³é…¸ï¼ˆATPï¼‰ã®å¤§éƒ¨åˆ†ã‚’ç”Ÿæˆã™ã‚‹ã“ã¨ã§ã™ã€‚</Answer>
+</Pair>
+<Pair>
+<Question>ATPã¯ç´°èƒå†…ã§ã©ã®ã‚ˆã†ã«åˆ©ç”¨ã•ã‚Œã¾ã™ã‹ï¼Ÿ</Question>
+<Answer><think>ATPã¯ã‚¢ãƒ‡ãƒã‚·ãƒ³ä¸‰ãƒªãƒ³é…¸ã§ã‚ã‚Šã€ãƒªãƒ³é…¸çµåˆã®åŠ æ°´åˆ†è§£ã«ã‚ˆã£ã¦ã‚¨ãƒãƒ«ã‚®ãƒ¼ã‚’æ”¾å‡ºã™ã‚‹ã€‚ã“ã®ã‚¨ãƒãƒ«ã‚®ãƒ¼ã¯ã‚¿ãƒ³ãƒ‘ã‚¯è³ªã®åˆæˆã€ç‰©è³ªã®è¼¸é€ã€ç´°èƒåˆ†è£‚ãªã©ã€ç´°èƒå†…ã®ã‚ã‚‰ã‚†ã‚‹ã‚¨ãƒãƒ«ã‚®ãƒ¼éœ€è¦ã«ä¾›çµ¦ã•ã‚Œã‚‹ã€‚</think>ATPã¯ç´°èƒå†…ã®æ§˜ã€…ãªåŒ–å­¦åå¿œã®ã‚¨ãƒãƒ«ã‚®ãƒ¼æºã¨ã—ã¦åˆ©ç”¨ã•ã‚Œã¾ã™ã€‚</Answer>
+</Pair>
+</QAPairs>
+\```
+
+ãã‚Œã§ã¯ã€æ€è€ƒãƒ•ãƒ­ãƒ¼ã‚’å«ã‚€Q&Aãƒšã‚¢ã®ç”Ÿæˆã‚’é–‹å§‹ã—ã¦ãã ã•ã„ã€‚
diff --git a/easy_dataset_cli/qa_generator.py b/easy_dataset_cli/qa_generator.py
index 0817065..545d830 100644
--- a/easy_dataset_cli/qa_generator.py
+++ b/easy_dataset_cli/qa_generator.py
@@ -3,15 +3,20 @@
 
 import os
 import xml.etree.ElementTree as ET
+from xml.dom import minidom
 from pathlib import Path
 from typing import List, Dict
 from litellm import completion
 from rich.console import Console
 from dotenv import load_dotenv
+import traceback
+import json
+from datetime import datetime
 
 from .prompts import (
     get_qa_generation_prompt,
     get_qa_generation_with_fulltext_prompt,
+    get_qa_generation_with_thinking_prompt,
     get_ga_definition_generation_prompt
 )
 from .xml_utils import parse_qa_from_text_fallback
@@ -43,36 +48,97 @@ def generate_qa_for_chunk_with_ga_and_fulltext(
     )
 
     messages = [
-        {"role": "system", "content": "ã‚ãªãŸã¯ã€XMLå½¢å¼ã§å³å¯†ã«å‡ºåŠ›ã™ã‚‹å„ªç§€ãªã‚¢ã‚·ã‚¹ã‚¿ãƒ³ãƒˆã§ã™ã€‚XMLã®ç‰¹æ®Šæ–‡å­—ï¼ˆ&, <, >, \", 'ï¼‰ã¯é©åˆ‡ã«ã‚¨ã‚¹ã‚±ãƒ¼ãƒ—ã—ã€æ”¹è¡Œã¯å«ã‚ãšã«å‡ºåŠ›ã—ã¦ãã ã•ã„ã€‚"},
+        {"role": "system", "content": "ã‚ãªãŸã¯ã€XMLå½¢å¼ã§å³å¯†ã«å‡ºåŠ›ã™ã‚‹å„ªç§€ãªã‚¢ã‚·ã‚¹ã‚¿ãƒ³ãƒˆã§ã™ã€‚é€šå¸¸ã®XMLã®ç‰¹æ®Šæ–‡å­—ï¼ˆ&, \", 'ï¼‰ã¯é©åˆ‡ã«ã‚¨ã‚¹ã‚±ãƒ¼ãƒ—ã—ã¦ãã ã•ã„ã€‚ãŸã ã—ã€<Question>ã€<Answer>ã€<think>ã‚¿ã‚°ã¯ãã®ã¾ã¾ä½¿ç”¨ã—ã¦ãã ã•ã„ã€‚æ”¹è¡Œã¯å«ã‚ãšã«å‡ºåŠ›ã—ã¦ãã ã•ã„ã€‚"},
         {"role": "user", "content": prompt}
     ]
 
     # OpenRouterç”¨ã®ç’°å¢ƒå¤‰æ•°è¨­å®š
     os.environ["OPENROUTER_API_KEY"] = os.getenv("OPENROUTER_API_KEY", "")
 
+    # ã‚¿ã‚¤ãƒ ã‚¹ã‚¿ãƒ³ãƒ—ä»˜ããƒ­ã‚°ãƒ•ã‚¡ã‚¤ãƒ«åã‚’ç”Ÿæˆ
+    timestamp = datetime.now().strftime("%Y%m%d_%H%M%S")
+    genre_safe = "".join(c for c in ga_pair['genre']['title'] if c.isalnum() or c in (' ', '-', '_')).strip().replace(' ', '_')
+    audience_safe = "".join(c for c in ga_pair['audience']['title'] if c.isalnum() or c in (' ', '-', '_')).strip().replace(' ', '_')
+    
     try:
+        # ãƒªã‚¯ã‚¨ã‚¹ãƒˆãƒ­ã‚°ã‚’ä¿å­˜
+        if logs_dir:
+            request_log = {
+                "timestamp": timestamp,
+                "model": model,
+                "genre": ga_pair['genre']['title'],
+                "audience": ga_pair['audience']['title'],
+                "prompt_length": len(prompt),
+                "messages": messages
+            }
+            request_filename = f"request_{genre_safe}_{audience_safe}_{timestamp}.json"
+            request_file_path = logs_dir / request_filename
+            with open(request_file_path, 'w', encoding='utf-8') as f:
+                json.dump(request_log, f, ensure_ascii=False, indent=2)
+            console.print(f"[dim]ãƒªã‚¯ã‚¨ã‚¹ãƒˆãƒ­ã‚°ã‚’ä¿å­˜: {request_filename}[/dim]")
+
         response = completion(model=model, messages=messages)
         xml_content = response.choices[0].message.content
 
+        # ãƒ¬ã‚¹ãƒãƒ³ã‚¹ãƒ­ã‚°ã‚’ä¿å­˜
+        if logs_dir:
+            response_log = {
+                "timestamp": timestamp,
+                "model": model,
+                "genre": ga_pair['genre']['title'],
+                "audience": ga_pair['audience']['title'],
+                "response_length": len(xml_content),
+                "response_content": xml_content
+            }
+            response_filename = f"response_{genre_safe}_{audience_safe}_{timestamp}.json"
+            response_file_path = logs_dir / response_filename
+            with open(response_file_path, 'w', encoding='utf-8') as f:
+                json.dump(response_log, f, ensure_ascii=False, indent=2)
+            console.print(f"[dim]ãƒ¬ã‚¹ãƒãƒ³ã‚¹ãƒ­ã‚°ã‚’ä¿å­˜: {response_filename}[/dim]")
+
         # rawãƒ¬ã‚¹ãƒãƒ³ã‚¹ã‚’ä¿å­˜ï¼ˆã‚ªãƒ—ã‚·ãƒ§ãƒ³ï¼‰
         if logs_dir:
-            genre_safe = "".join(c for c in ga_pair['genre']['title'] if c.isalnum() or c in (' ', '-', '_')).strip().replace(' ', '_')
-            audience_safe = "".join(c for c in ga_pair['audience']['title'] if c.isalnum() or c in (' ', '-', '_')).strip().replace(' ', '_')
-            raw_filename = f"qa_fulltext_raw_{genre_safe}_{audience_safe}.md"
+            raw_filename = f"qa_fulltext_raw_{genre_safe}_{audience_safe}_{timestamp}.md"
             raw_file_path = logs_dir / raw_filename
             raw_file_path.write_text(xml_content, encoding="utf-8")
 
-        return _parse_qa_response(xml_content)
+        qa_pairs = _parse_qa_response(xml_content, logs_dir, genre_safe, audience_safe, timestamp)
+        
+        # ç”Ÿæˆã—ãŸQAã‚’ä¿å­˜
+        if qa_pairs and logs_dir:
+            qa_filename = f"qa_pairs_{genre_safe}_{audience_safe}_{timestamp}.xml"
+            qa_file_path = logs_dir / qa_filename
+            
+            _save_qa_pairs_to_xml(qa_pairs, logs_dir, qa_filename)
+
+        return qa_pairs
 
     except Exception as general_error:
-        console.print(
-            f"[bold red]ãƒãƒ£ãƒ³ã‚¯ã¨GAãƒšã‚¢ã‹ã‚‰ã®Q&Aç”Ÿæˆä¸­ã«ã‚¨ãƒ©ãƒ¼ãŒç™ºç”Ÿã—ã¾ã—ãŸ:[/bold red] "
-            f"{general_error}"
-        )
-        console.print(
-            f"[dim]Genre: {ga_pair['genre']['title']}, "
-            f"Audience: {ga_pair['audience']['title']}[/dim]"
-        )
+        # è©³ç´°ãªã‚¨ãƒ©ãƒ¼æƒ…å ±ã‚’è¡¨ç¤º
+        console.print(f"[bold red]ãƒãƒ£ãƒ³ã‚¯ã¨GAãƒšã‚¢ã‹ã‚‰ã®Q&Aç”Ÿæˆä¸­ã«ã‚¨ãƒ©ãƒ¼ãŒç™ºç”Ÿã—ã¾ã—ãŸ:[/bold red]")
+        console.print(f"[bold red]ã‚¨ãƒ©ãƒ¼ã‚¿ã‚¤ãƒ—:[/bold red] {type(general_error).__name__}")
+        console.print(f"[bold red]ã‚¨ãƒ©ãƒ¼ãƒ¡ãƒƒã‚»ãƒ¼ã‚¸:[/bold red] {str(general_error)}")
+        console.print(f"[bold red]ãƒˆãƒ¬ãƒ¼ã‚¹ãƒãƒƒã‚¯:[/bold red]")
+        console.print(traceback.format_exc())
+        console.print(f"[dim]Genre: {ga_pair['genre']['title']}, Audience: {ga_pair['audience']['title']}[/dim]")
+        
+        # ã‚¨ãƒ©ãƒ¼ãƒ­ã‚°ã‚’ä¿å­˜
+        if logs_dir:
+            error_log = {
+                "timestamp": timestamp,
+                "model": model,
+                "genre": ga_pair['genre']['title'],
+                "audience": ga_pair['audience']['title'],
+                "error_type": type(general_error).__name__,
+                "error_message": str(general_error),
+                "traceback": traceback.format_exc()
+            }
+            error_filename = f"error_{genre_safe}_{audience_safe}_{timestamp}.json"
+            error_file_path = logs_dir / error_filename
+            with open(error_file_path, 'w', encoding='utf-8') as f:
+                json.dump(error_log, f, ensure_ascii=False, indent=2)
+            console.print(f"[dim]ã‚¨ãƒ©ãƒ¼ãƒ­ã‚°ã‚’ä¿å­˜: {error_filename}[/dim]")
+        
         return []
 
 
@@ -95,36 +161,97 @@ def generate_qa_for_chunk_with_ga(
     )
 
     messages = [
-        {"role": "system", "content": "ã‚ãªãŸã¯ã€XMLå½¢å¼ã§å³å¯†ã«å‡ºåŠ›ã™ã‚‹å„ªç§€ãªã‚¢ã‚·ã‚¹ã‚¿ãƒ³ãƒˆã§ã™ã€‚XMLã®ç‰¹æ®Šæ–‡å­—ï¼ˆ&, <, >, \", 'ï¼‰ã¯é©åˆ‡ã«ã‚¨ã‚¹ã‚±ãƒ¼ãƒ—ã—ã€æ”¹è¡Œã¯å«ã‚ãšã«å‡ºåŠ›ã—ã¦ãã ã•ã„ã€‚"},
+        {"role": "system", "content": "ã‚ãªãŸã¯ã€XMLå½¢å¼ã§å³å¯†ã«å‡ºåŠ›ã™ã‚‹å„ªç§€ãªã‚¢ã‚·ã‚¹ã‚¿ãƒ³ãƒˆã§ã™ã€‚é€šå¸¸ã®XMLã®ç‰¹æ®Šæ–‡å­—ï¼ˆ&, \", 'ï¼‰ã¯é©åˆ‡ã«ã‚¨ã‚¹ã‚±ãƒ¼ãƒ—ã—ã¦ãã ã•ã„ã€‚ãŸã ã—ã€<Question>ã€<Answer>ã€<think>ã‚¿ã‚°ã¯ãã®ã¾ã¾ä½¿ç”¨ã—ã¦ãã ã•ã„ã€‚æ”¹è¡Œã¯å«ã‚ãšã«å‡ºåŠ›ã—ã¦ãã ã•ã„ã€‚"},
         {"role": "user", "content": prompt}
     ]
 
     # OpenRouterç”¨ã®ç’°å¢ƒå¤‰æ•°è¨­å®š
     os.environ["OPENROUTER_API_KEY"] = os.getenv("OPENROUTER_API_KEY", "")
 
+    # ã‚¿ã‚¤ãƒ ã‚¹ã‚¿ãƒ³ãƒ—ä»˜ããƒ­ã‚°ãƒ•ã‚¡ã‚¤ãƒ«åã‚’ç”Ÿæˆ
+    timestamp = datetime.now().strftime("%Y%m%d_%H%M%S")
+    genre_safe = "".join(c for c in ga_pair['genre']['title'] if c.isalnum() or c in (' ', '-', '_')).strip().replace(' ', '_')
+    audience_safe = "".join(c for c in ga_pair['audience']['title'] if c.isalnum() or c in (' ', '-', '_')).strip().replace(' ', '_')
+    
     try:
+        # ãƒªã‚¯ã‚¨ã‚¹ãƒˆãƒ­ã‚°ã‚’ä¿å­˜
+        if logs_dir:
+            request_log = {
+                "timestamp": timestamp,
+                "model": model,
+                "genre": ga_pair['genre']['title'],
+                "audience": ga_pair['audience']['title'],
+                "prompt_length": len(prompt),
+                "messages": messages
+            }
+            request_filename = f"request_{genre_safe}_{audience_safe}_{timestamp}.json"
+            request_file_path = logs_dir / request_filename
+            with open(request_file_path, 'w', encoding='utf-8') as f:
+                json.dump(request_log, f, ensure_ascii=False, indent=2)
+            console.print(f"[dim]ãƒªã‚¯ã‚¨ã‚¹ãƒˆãƒ­ã‚°ã‚’ä¿å­˜: {request_filename}[/dim]")
+
         response = completion(model=model, messages=messages)
         xml_content = response.choices[0].message.content
 
+        # ãƒ¬ã‚¹ãƒãƒ³ã‚¹ãƒ­ã‚°ã‚’ä¿å­˜
+        if logs_dir:
+            response_log = {
+                "timestamp": timestamp,
+                "model": model,
+                "genre": ga_pair['genre']['title'],
+                "audience": ga_pair['audience']['title'],
+                "response_length": len(xml_content),
+                "response_content": xml_content
+            }
+            response_filename = f"response_{genre_safe}_{audience_safe}_{timestamp}.json"
+            response_file_path = logs_dir / response_filename
+            with open(response_file_path, 'w', encoding='utf-8') as f:
+                json.dump(response_log, f, ensure_ascii=False, indent=2)
+            console.print(f"[dim]ãƒ¬ã‚¹ãƒãƒ³ã‚¹ãƒ­ã‚°ã‚’ä¿å­˜: {response_filename}[/dim]")
+
         # rawãƒ¬ã‚¹ãƒãƒ³ã‚¹ã‚’ä¿å­˜ï¼ˆã‚ªãƒ—ã‚·ãƒ§ãƒ³ï¼‰
         if logs_dir:
-            genre_safe = "".join(c for c in ga_pair['genre']['title'] if c.isalnum() or c in (' ', '-', '_')).strip().replace(' ', '_')
-            audience_safe = "".join(c for c in ga_pair['audience']['title'] if c.isalnum() or c in (' ', '-', '_')).strip().replace(' ', '_')
-            raw_filename = f"qa_raw_{genre_safe}_{audience_safe}.md"
+            raw_filename = f"qa_raw_{genre_safe}_{audience_safe}_{timestamp}.md"
             raw_file_path = logs_dir / raw_filename
             raw_file_path.write_text(xml_content, encoding="utf-8")
 
-        return _parse_qa_response(xml_content)
+        qa_pairs = _parse_qa_response(xml_content, logs_dir, genre_safe, audience_safe, timestamp)
+        
+        # ç”Ÿæˆã—ãŸQAã‚’ä¿å­˜
+        if qa_pairs and logs_dir:
+            qa_filename = f"qa_pairs_{genre_safe}_{audience_safe}_{timestamp}.xml"
+            qa_file_path = logs_dir / qa_filename
+            
+            _save_qa_pairs_to_xml(qa_pairs, logs_dir, qa_filename)
+
+        return qa_pairs
 
     except Exception as general_error:
-        console.print(
-            f"[bold red]ãƒãƒ£ãƒ³ã‚¯ã¨GAãƒšã‚¢ã‹ã‚‰ã®Q&Aç”Ÿæˆä¸­ã«ã‚¨ãƒ©ãƒ¼ãŒç™ºç”Ÿã—ã¾ã—ãŸ:[/bold red] "
-            f"{general_error}"
-        )
-        console.print(
-            f"[dim]Genre: {ga_pair['genre']['title']}, "
-            f"Audience: {ga_pair['audience']['title']}[/dim]"
-        )
+        # è©³ç´°ãªã‚¨ãƒ©ãƒ¼æƒ…å ±ã‚’è¡¨ç¤º
+        console.print(f"[bold red]ãƒãƒ£ãƒ³ã‚¯ã¨GAãƒšã‚¢ã‹ã‚‰ã®Q&Aç”Ÿæˆä¸­ã«ã‚¨ãƒ©ãƒ¼ãŒç™ºç”Ÿã—ã¾ã—ãŸ:[/bold red]")
+        console.print(f"[bold red]ã‚¨ãƒ©ãƒ¼ã‚¿ã‚¤ãƒ—:[/bold red] {type(general_error).__name__}")
+        console.print(f"[bold red]ã‚¨ãƒ©ãƒ¼ãƒ¡ãƒƒã‚»ãƒ¼ã‚¸:[/bold red] {str(general_error)}")
+        console.print(f"[bold red]ãƒˆãƒ¬ãƒ¼ã‚¹ãƒãƒƒã‚¯:[/bold red]")
+        console.print(traceback.format_exc())
+        console.print(f"[dim]Genre: {ga_pair['genre']['title']}, Audience: {ga_pair['audience']['title']}[/dim]")
+        
+        # ã‚¨ãƒ©ãƒ¼ãƒ­ã‚°ã‚’ä¿å­˜
+        if logs_dir:
+            error_log = {
+                "timestamp": timestamp,
+                "model": model,
+                "genre": ga_pair['genre']['title'],
+                "audience": ga_pair['audience']['title'],
+                "error_type": type(general_error).__name__,
+                "error_message": str(general_error),
+                "traceback": traceback.format_exc()
+            }
+            error_filename = f"error_{genre_safe}_{audience_safe}_{timestamp}.json"
+            error_file_path = logs_dir / error_filename
+            with open(error_file_path, 'w', encoding='utf-8') as f:
+                json.dump(error_log, f, ensure_ascii=False, indent=2)
+            console.print(f"[dim]ã‚¨ãƒ©ãƒ¼ãƒ­ã‚°ã‚’ä¿å­˜: {error_filename}[/dim]")
+        
         return []
 
 
@@ -173,16 +300,61 @@ def generate_ga_definitions(text_content: str, model: str, num_ga_pairs: int = N
         raise
 
 
-def _parse_qa_response(xml_content: str) -> List[Dict[str, str]]:
+def _parse_qa_response(xml_content: str, logs_dir: Path = None, genre_safe: str = None, audience_safe: str = None, timestamp: str = None) -> List[Dict[str, str]]:
     """Q&Aç”Ÿæˆãƒ¬ã‚¹ãƒãƒ³ã‚¹ã®XMLã‚’è§£æã™ã‚‹ï¼ˆå…±é€šå‡¦ç†ï¼‰"""
     qa_pairs = []
 
-    # LLMã‹ã‚‰ã®å‡ºåŠ›ã«ã¯ä½™åˆ†ãªãƒ†ã‚­ã‚¹ãƒˆãŒå«ã¾ã‚Œã‚‹ã“ã¨ãŒã‚ã‚‹ãŸã‚ã€XMLéƒ¨åˆ†ã®ã¿ã‚’æŠ½å‡º
-    xml_start = xml_content.find("<QAPairs>")
-    xml_end = xml_content.rfind("</QAPairs>")
+    # LLMã‹ã‚‰ã®å‡ºåŠ›ã®å‰å‡¦ç†ï¼šä¸è¦ãªãƒ†ã‚­ã‚¹ãƒˆã‚’é™¤å»
+    cleaned_content = _clean_llm_response(xml_content)
+    
+    # XMLéƒ¨åˆ†ã®ã¿ã‚’æŠ½å‡º - å„ªå…ˆçš„ã«<QAPairs>ã‚¿ã‚°ã‚’æ¢ã™
+    xml_start = cleaned_content.find("<QAPairs>")
+    xml_end = cleaned_content.rfind("</QAPairs>")
+    
+    # <QAPairs>ã‚¿ã‚°ãŒè¦‹ã¤ã‹ã‚‰ãªã„å ´åˆã¯<Pair>ã‚¿ã‚°ã§æŠ½å‡ºã‚’è©¦è¡Œ
+    if xml_start == -1 or xml_end == -1:
+        console.print("[yellow]<QAPairs>ã‚¿ã‚°ãŒè¦‹ã¤ã‹ã‚‰ãªã„ãŸã‚ã€<Pair>ã‚¿ã‚°ã§æŠ½å‡ºã‚’è©¦è¡Œã—ã¾ã™...[/yellow]")
+        xml_start = cleaned_content.find("<Pair>")
+        xml_end = cleaned_content.rfind("</Pair>")
+        
+        # <Pair>ã‚¿ã‚°ã§å›²ã¾ã‚ŒãŸéƒ¨åˆ†ã‚’æŠ½å‡º
+        if xml_start != -1 and xml_end != -1:
+            # ã™ã¹ã¦ã®<Pair>...</Pair>ã‚’æŠ½å‡º
+            import re
+            pair_pattern = r'<Pair>.*?</Pair>'
+            pair_matches = re.findall(pair_pattern, cleaned_content, re.DOTALL)
+            
+            for pair_match in pair_matches:
+                # å„Pairã‹ã‚‰Questionã¨Answerã‚’æŠ½å‡º
+                question_match = re.search(r'<Question>(.*?)</Question>', pair_match, re.DOTALL)
+                answer_match = re.search(r'<Answer>(.*?)</Answer>', pair_match, re.DOTALL)
+                
+                if question_match and answer_match:
+                    qa_pairs.append({
+                        "question": _decode_xml_entities(question_match.group(1).strip()),
+                        "answer": _decode_xml_entities(answer_match.group(1).strip())
+                    })
+            
+            if qa_pairs:
+                console.print(f"[green]âœ“[/green] <Pair>ã‚¿ã‚°ã‹ã‚‰{len(qa_pairs)}ä»¶ã®Q&Aã‚’æŠ½å‡ºã—ã¾ã—ãŸ")
+                return qa_pairs
 
     if xml_start != -1 and xml_end != -1:
-        clean_xml = xml_content[xml_start: xml_end + len("</QAPairs>")]
+        clean_xml = cleaned_content[xml_start: xml_end + len("</QAPairs>")]
+        
+        # XMLè§£æç”¨ã®ãƒ­ã‚°ã‚’ä¿å­˜
+        if logs_dir and genre_safe and audience_safe and timestamp:
+            xml_debug_log = {
+                "timestamp": timestamp,
+                "original_xml_content": xml_content[:500],
+                "cleaned_xml_content": cleaned_content[:500],
+                "final_xml_content": clean_xml,
+                "xml_length": len(clean_xml)
+            }
+            xml_debug_filename = f"xml_debug_{genre_safe}_{audience_safe}_{timestamp}.json"
+            xml_debug_file_path = logs_dir / xml_debug_filename
+            with open(xml_debug_file_path, 'w', encoding='utf-8') as f:
+                json.dump(xml_debug_log, f, ensure_ascii=False, indent=2)
 
         try:
             root = ET.fromstring(clean_xml)
@@ -192,18 +364,318 @@ def _parse_qa_response(xml_content: str) -> List[Dict[str, str]]:
                 answer_node = pair_node.find('Answer')
 
                 if question_node is not None and answer_node is not None:
+                    question_text = question_node.text or ""
+                    
+                    # <Answer>è¦ç´ å†…ã®å†…å®¹ã‚’é©åˆ‡ã«å–å¾—
+                    if len(answer_node) > 0:
+                        # ã‚µãƒ–ã‚¨ãƒ¬ãƒ¡ãƒ³ãƒˆãŒã‚ã‚‹å ´åˆï¼ˆ<think>ã‚¿ã‚°ãªã©ï¼‰
+                        answer_parts = []
+                        
+                        # Answerè¦ç´ ã®ç›´æ¥ã®ãƒ†ã‚­ã‚¹ãƒˆï¼ˆ<think>ã‚ˆã‚Šå‰ï¼‰
+                        if answer_node.text:
+                            answer_parts.append(answer_node.text.strip())
+                        
+                        # å„ã‚µãƒ–ã‚¨ãƒ¬ãƒ¡ãƒ³ãƒˆã®tailï¼ˆã‚µãƒ–ã‚¨ãƒ¬ãƒ¡ãƒ³ãƒˆã®å¾Œã®ãƒ†ã‚­ã‚¹ãƒˆï¼‰
+                        for child in answer_node:
+                            if child.tag == 'think':
+                                # <think>ã‚¿ã‚°ã®å†…å®¹ã‚’å–å¾—
+                                think_content = child.text or ""
+                                answer_parts.append(f"<think>{think_content}</think>")
+                            
+                            # ã‚µãƒ–ã‚¨ãƒ¬ãƒ¡ãƒ³ãƒˆã®å¾Œã®ãƒ†ã‚­ã‚¹ãƒˆ
+                            if child.tail:
+                                answer_parts.append(child.tail.strip())
+                        
+                        answer_text = "".join(answer_parts)
+                    else:
+                        # ã‚µãƒ–ã‚¨ãƒ¬ãƒ¡ãƒ³ãƒˆãŒãªã„å ´åˆã¯é€šå¸¸ã®ãƒ†ã‚­ã‚¹ãƒˆ
+                        answer_text = answer_node.text or ""
+                    
+                    # XMLã‚¨ãƒ³ãƒ†ã‚£ãƒ†ã‚£ãƒ‡ã‚³ãƒ¼ãƒ‰
+                    question_text = _decode_xml_entities(question_text)
+                    answer_text = _decode_xml_entities(answer_text)
+                    
                     qa_pairs.append({
-                        "question": question_node.text or "",
-                        "answer": answer_node.text or ""
+                        "question": question_text,
+                        "answer": answer_text
                     })
 
-        except ET.ParseError:
+        except ET.ParseError as parse_error:
             # XMLãƒ‘ãƒ¼ã‚¹ã«å¤±æ•—ã—ãŸå ´åˆã€æ‰‹å‹•ã§ãƒ†ã‚­ã‚¹ãƒˆè§£æ
-            console.print("[yellow]XMLãƒ‘ãƒ¼ã‚¹ã‚¨ãƒ©ãƒ¼ã€æ‰‹å‹•è§£æã‚’è©¦è¡Œä¸­...[/yellow]")
+            console.print("[yellow]XMLãƒ‘ãƒ¼ã‚¹ã‚¨ãƒ©ãƒ¼ã€è‡ªå‹•è§£æã‚’è©¦è¡Œä¸­...[/yellow]")
+            console.print(f"[dim]ãƒ‘ãƒ¼ã‚¹ã‚¨ãƒ©ãƒ¼è©³ç´°: {str(parse_error)}[/dim]")
+            
+            # ã‚¨ãƒ©ãƒ¼ãƒ­ã‚°ã‚’ä¿å­˜
+            if logs_dir and genre_safe and audience_safe and timestamp:
+                parse_error_log = {
+                    "timestamp": timestamp,
+                    "error_type": "XML_ParseError",
+                    "error_message": str(parse_error),
+                    "xml_content": clean_xml
+                }
+                parse_error_filename = f"xml_parse_error_{genre_safe}_{audience_safe}_{timestamp}.json"
+                parse_error_file_path = logs_dir / parse_error_filename
+                with open(parse_error_file_path, 'w', encoding='utf-8') as f:
+                    json.dump(parse_error_log, f, ensure_ascii=False, indent=2)
+            
+            # è‡ªå‹•è§£æã‚’è©¦è¡Œ
             qa_pairs = parse_qa_from_text_fallback(clean_xml)
+            
+            # è‡ªå‹•è§£æã§ã‚‚å¤±æ•—ã—ãŸå ´åˆã®ãƒ•ã‚©ãƒ¼ãƒ«ãƒãƒƒã‚¯
+            if not qa_pairs:
+                console.print("[yellow]è‡ªå‹•è§£æã‚‚å¤±æ•—ã—ãŸãŸã‚ã€ãƒ†ã‚­ã‚¹ãƒˆã‹ã‚‰ç›´æ¥Q&Aã‚’æŠ½å‡ºã—ã¾ã™...[/yellow]")
+                qa_pairs = _extract_qa_from_fallback_text(cleaned_content)
 
     if not qa_pairs:
         console.print(f"[bold red]LLMãŒç”Ÿæˆã—ãŸXMLã®è§£æã«å¤±æ•—ã—ã¾ã—ãŸ[/bold red]")
-        console.print(f"[dim]å—ä¿¡ã—ãŸãƒ†ã‚­ã‚¹ãƒˆ: {xml_content[:200]}...[/dim]")
+        console.print(f"[dim]å—ä¿¡ã—ãŸãƒ†ã‚­ã‚¹ãƒˆ: {cleaned_content[:500]}...[/dim]")
+        
+        # è§£æå¤±æ•—ã®ãƒ­ã‚°ã‚’ä¿å­˜
+        if logs_dir and genre_safe and audience_safe and timestamp:
+            failure_log = {
+                "timestamp": timestamp,
+                "failure_reason": "XMLè§£æå¤±æ•—",
+                "original_content": xml_content[:1000],
+                "cleaned_content": cleaned_content[:1000]
+            }
+            failure_filename = f"xml_parse_failure_{genre_safe}_{audience_safe}_{timestamp}.json"
+            failure_file_path = logs_dir / failure_filename
+            with open(failure_file_path, 'w', encoding='utf-8') as f:
+                json.dump(failure_log, f, ensure_ascii=False, indent=2)
+
+    return qa_pairs
+
 
+def _clean_llm_response(response: str) -> str:
+    """LLMã‹ã‚‰ã®ãƒ¬ã‚¹ãƒãƒ³ã‚¹ã‚’ã‚¯ãƒªãƒ¼ãƒ³ã‚¢ãƒƒãƒ—ã™ã‚‹"""
+    import re
+    
+    # ä¸è¦ãªãƒ†ã‚­ã‚¹ãƒˆã‚’é™¤å»
+    cleaned = response
+    
+    # \```xml ... \``` ã®ã‚ˆã†ãªã‚³ãƒ¼ãƒ‰ãƒ–ãƒ­ãƒƒã‚¯ã‚’é™¤å»
+    cleaned = re.sub(r'\```xml\s*|\s*\```', '', cleaned, flags=re.IGNORECASE)
+    
+    # \``` ... \``` ã®ã‚ˆã†ãªã‚³ãƒ¼ãƒ‰ãƒ–ãƒ­ãƒƒã‚¯ã‚’é™¤å»
+    cleaned = re.sub(r'\```\s*|\s*\```', '', cleaned)
+    
+    # <xml> ... </xml> ã®ã‚ˆã†ãªã‚¿ã‚°ã‚’é™¤å»
+    cleaned = re.sub(r'<xml>\s*|\s*</xml>', '', cleaned, flags=re.IGNORECASE)
+    
+    # ä¸è¦ãªç©ºç™½ã‚„æ”¹è¡Œã‚’æ•´ç†
+    cleaned = re.sub(r'\s+', ' ', cleaned).strip()
+    
+    return cleaned
+
+
+def _extract_qa_from_fallback_text(text: str) -> List[Dict[str, str]]:
+    """ãƒ†ã‚­ã‚¹ãƒˆã‹ã‚‰ç›´æ¥Q&Aã‚’æŠ½å‡ºã™ã‚‹ãƒ•ã‚©ãƒ¼ãƒ«ãƒãƒƒã‚¯é–¢æ•°"""
+    qa_pairs = []
+    
+    try:
+        # <Question>ã¨<Answer>ã‚¿ã‚°ã§åˆ†å‰²
+        import re
+        
+        # Questionã‚¿ã‚°ã‚’æ¤œç´¢
+        question_pattern = r'<Question>(.*?)</Question>'
+        answer_pattern = r'<Answer>(.*?)</Answer>'
+        
+        questions = re.findall(question_pattern, text, re.DOTALL)
+        answers = re.findall(answer_pattern, text, re.DOTALL)
+        
+        # åŒã˜æ•°ã®è³ªå•ã¨å›ç­”ãŒã‚ã‚‹å ´åˆã®ã¿ãƒšã‚¢ã‚’ä½œæˆ
+        min_count = min(len(questions), len(answers))
+        for i in range(min_count):
+            qa_pairs.append({
+                "question": _decode_xml_entities(questions[i].strip()),
+                "answer": _decode_xml_entities(answers[i].strip())
+            })
+            
+    except Exception as e:
+        console.print(f"[red]ãƒ•ã‚©ãƒ¼ãƒ«ãƒãƒƒã‚¯è§£æã‚‚å¤±æ•—:[/red] {e}")
+    
     return qa_pairs
+
+
+def _decode_xml_entities(text: str) -> str:
+    """XMLã‚¨ãƒ³ãƒ†ã‚£ãƒ†ã‚£ã‚’ãƒ‡ã‚³ãƒ¼ãƒ‰ã™ã‚‹ï¼ˆã‚·ãƒ³ãƒ—ãƒ«ç‰ˆï¼‰"""
+    import html
+    if text:
+        return html.unescape(text)
+    return text
+
+
+def _parse_answer_with_think(answer_text: str) -> Dict[str, str]:
+    """<think>ã‚¿ã‚°ã‚’å«ã‚€å›ç­”ã‚’ãƒ‘ãƒ¼ã‚¹ã—ã¦åˆ†é›¢"""
+    import re
+    
+    # <think>...</think>ã‚¿ã‚°ã‚’æ¤œç´¢
+    think_match = re.search(r'<think>(.*?)</think>', answer_text, re.DOTALL)
+    
+    if think_match:
+        think_content = think_match.group(1).strip()
+        # <think>ã‚¿ã‚°ä»¥é™ã®å›ç­”ãƒ†ã‚­ã‚¹ãƒˆã‚’å–å¾—
+        answer_content = answer_text[think_match.end():].strip()
+        return {
+            "has_think": True,
+            "think_content": think_content,
+            "answer_content": answer_content
+        }
+    else:
+        return {
+            "has_think": False,
+            "think_content": "",
+            "answer_content": answer_text
+        }
+
+
+def _save_qa_pairs_to_xml(qa_pairs: List[Dict[str, str]], logs_dir: Path, qa_filename: str) -> None:
+    """Q&Aãƒšã‚¢ã‚’ãã‚Œã„ã«æ•´å½¢ã•ã‚ŒãŸXMLãƒ•ã‚¡ã‚¤ãƒ«ã¨ã—ã¦ä¿å­˜ï¼ˆã‚µãƒ–ã‚¨ãƒ¬ãƒ¡ãƒ³ãƒˆæ–¹å¼ï¼‰"""
+    if not qa_pairs or not logs_dir:
+        return
+        
+    qa_file_path = logs_dir / qa_filename
+    
+    # ElementTreeã§æ§‹é€ åŒ–ç”Ÿæˆ
+    root = ET.Element("QAPairs")
+    for qa in qa_pairs:
+        pair_elem = ET.SubElement(root, "Pair")
+        question_elem = ET.SubElement(pair_elem, "Question")
+        question_elem.text = qa["question"]
+        
+        answer_elem = ET.SubElement(pair_elem, "Answer")
+        
+        # å›ç­”å†…å®¹ã‚’è§£æ
+        parsed_answer = _parse_answer_with_think(qa["answer"])
+        
+        if parsed_answer["has_think"]:
+            # <think>ã‚’ã‚µãƒ–ã‚¨ãƒ¬ãƒ¡ãƒ³ãƒˆã¨ã—ã¦è¿½åŠ 
+            think_elem = ET.SubElement(answer_elem, "think")
+            think_elem.text = parsed_answer["think_content"]
+            think_elem.tail = parsed_answer["answer_content"]
+        else:
+            # é€šå¸¸ã®å›ç­”
+            answer_elem.text = parsed_answer["answer_content"]
+    
+    # æ•´å½¢ã—ã¦ä¿å­˜
+    rough_string = ET.tostring(root, 'utf-8')
+    reparsed = minidom.parseString(rough_string)
+    pretty_xml = reparsed.toprettyxml(indent="  ")
+    
+    qa_file_path.write_text(pretty_xml, encoding='utf-8')
+    console.print(f"[green]âœ“[/green] QAãƒšã‚¢ã‚’ä¿å­˜: {qa_filename} ({len(qa_pairs)}ä»¶)")
+
+
+def generate_qa_for_chunk_with_ga_and_thinking(
+    chunk: str,
+    full_text: str,
+    model: str,
+    ga_pair: Dict[str, Dict[str, str]],
+    logs_dir: Path = None,
+    num_qa_pairs: int = None
+) -> List[Dict[str, str]]:
+    """litellmã‚’ä½¿ã„ã€1ã¤ã®ãƒãƒ£ãƒ³ã‚¯ã¨å…¨æ–‡ã€1ã¤ã®GAãƒšã‚¢ã‹ã‚‰æ€è€ƒãƒ•ãƒ­ãƒ¼ä»˜ãQ&Aãƒšã‚¢ã®ãƒªã‚¹ãƒˆã‚’ç”Ÿæˆã™ã‚‹"""
+    prompt_template = get_qa_generation_with_thinking_prompt()
+    prompt = prompt_template.format(
+        chunk=chunk,
+        full_text=full_text,
+        genre_title=ga_pair['genre']['title'],
+        genre_description=ga_pair['genre']['description'],
+        audience_title=ga_pair['audience']['title'],
+        audience_description=ga_pair['audience']['description'],
+        num_qa_pairs=num_qa_pairs if num_qa_pairs is not None else "è¤‡æ•°ã®"
+    )
+
+    messages = [
+        {"role": "system", "content": "ã‚ãªãŸã¯ã€XMLå½¢å¼ã§å³å¯†ã«å‡ºåŠ›ã™ã‚‹å„ªç§€ãªã‚¢ã‚·ã‚¹ã‚¿ãƒ³ãƒˆã§ã™ã€‚é€šå¸¸ã®XMLã®ç‰¹æ®Šæ–‡å­—ï¼ˆ&, \", 'ï¼‰ã¯é©åˆ‡ã«ã‚¨ã‚¹ã‚±ãƒ¼ãƒ—ã—ã¦ãã ã•ã„ã€‚ãŸã ã—ã€<Question>ã€<Answer>ã€<think>ã‚¿ã‚°ã¯ãã®ã¾ã¾ä½¿ç”¨ã—ã¦ãã ã•ã„ã€‚æ”¹è¡Œã¯å«ã‚ãšã«å‡ºåŠ›ã—ã¦ãã ã•ã„ã€‚"},
+        {"role": "user", "content": prompt}
+    ]
+
+    # OpenRouterç”¨ã®ç’°å¢ƒå¤‰æ•°è¨­å®š
+    os.environ["OPENROUTER_API_KEY"] = os.getenv("OPENROUTER_API_KEY", "")
+
+    # ã‚¿ã‚¤ãƒ ã‚¹ã‚¿ãƒ³ãƒ—ä»˜ããƒ­ã‚°ãƒ•ã‚¡ã‚¤ãƒ«åã‚’ç”Ÿæˆ
+    timestamp = datetime.now().strftime("%Y%m%d_%H%M%S")
+    genre_safe = "".join(c for c in ga_pair['genre']['title'] if c.isalnum() or c in (' ', '-', '_')).strip().replace(' ', '_')
+    audience_safe = "".join(c for c in ga_pair['audience']['title'] if c.isalnum() or c in (' ', '-', '_')).strip().replace(' ', '_')
+    
+    try:
+        # ãƒªã‚¯ã‚¨ã‚¹ãƒˆãƒ­ã‚°ã‚’ä¿å­˜
+        if logs_dir:
+            request_log = {
+                "timestamp": timestamp,
+                "model": model,
+                "genre": ga_pair['genre']['title'],
+                "audience": ga_pair['audience']['title'],
+                "prompt_length": len(prompt),
+                "messages": messages
+            }
+            request_filename = f"request_thinking_{genre_safe}_{audience_safe}_{timestamp}.json"
+            request_file_path = logs_dir / request_filename
+            with open(request_file_path, 'w', encoding='utf-8') as f:
+                json.dump(request_log, f, ensure_ascii=False, indent=2)
+            console.print(f"[dim]ãƒªã‚¯ã‚¨ã‚¹ãƒˆãƒ­ã‚°ã‚’ä¿å­˜: {request_filename}[/dim]")
+
+        response = completion(model=model, messages=messages)
+        xml_content = response.choices[0].message.content
+
+        # ãƒ¬ã‚¹ãƒãƒ³ã‚¹ãƒ­ã‚°ã‚’ä¿å­˜
+        if logs_dir:
+            response_log = {
+                "timestamp": timestamp,
+                "model": model,
+                "genre": ga_pair['genre']['title'],
+                "audience": ga_pair['audience']['title'],
+                "response_length": len(xml_content),
+                "response_content": xml_content
+            }
+            response_filename = f"response_thinking_{genre_safe}_{audience_safe}_{timestamp}.json"
+            response_file_path = logs_dir / response_filename
+            with open(response_file_path, 'w', encoding='utf-8') as f:
+                json.dump(response_log, f, ensure_ascii=False, indent=2)
+            console.print(f"[dim]ãƒ¬ã‚¹ãƒãƒ³ã‚¹ãƒ­ã‚°ã‚’ä¿å­˜: {response_filename}[/dim]")
+
+        # rawãƒ¬ã‚¹ãƒãƒ³ã‚¹ã‚’ä¿å­˜ï¼ˆã‚ªãƒ—ã‚·ãƒ§ãƒ³ï¼‰
+        if logs_dir:
+            raw_filename = f"qa_thinking_raw_{genre_safe}_{audience_safe}_{timestamp}.md"
+            raw_file_path = logs_dir / raw_filename
+            raw_file_path.write_text(xml_content, encoding="utf-8")
+
+        qa_pairs = _parse_qa_response(xml_content, logs_dir, genre_safe, audience_safe, timestamp)
+
+        # ç”Ÿæˆã—ãŸQAã‚’ä¿å­˜
+        if qa_pairs and logs_dir:
+            qa_filename = f"qa_pairs_thinking_{genre_safe}_{audience_safe}_{timestamp}.xml"
+            _save_qa_pairs_to_xml(qa_pairs, logs_dir, qa_filename)
+
+        return qa_pairs
+
+    except Exception as general_error:
+        # è©³ç´°ãªã‚¨ãƒ©ãƒ¼æƒ…å ±ã‚’è¡¨ç¤º
+        console.print(f"[bold red]ãƒãƒ£ãƒ³ã‚¯ã¨GAãƒšã‚¢ã‹ã‚‰ã®æ€è€ƒãƒ•ãƒ­ãƒ¼ä»˜ãQ&Aç”Ÿæˆä¸­ã«ã‚¨ãƒ©ãƒ¼ãŒç™ºç”Ÿã—ã¾ã—ãŸ:[/bold red]")
+        console.print(f"[bold red]ã‚¨ãƒ©ãƒ¼ã‚¿ã‚¤ãƒ—:[/bold red] {type(general_error).__name__}")
+        console.print(f"[bold red]ã‚¨ãƒ©ãƒ¼ãƒ¡ãƒƒã‚»ãƒ¼ã‚¸:[/bold red] {str(general_error)}")
+        console.print(f"[bold red]ãƒˆãƒ¬ãƒ¼ã‚¹ãƒãƒƒã‚¯:[/bold red]")
+        console.print(traceback.format_exc())
+        console.print(f"[dim]Genre: {ga_pair['genre']['title']}, Audience: {ga_pair['audience']['title']}[/dim]")
+        
+        # ã‚¨ãƒ©ãƒ¼ãƒ­ã‚°ã‚’ä¿å­˜
+        if logs_dir:
+            error_log = {
+                "timestamp": timestamp,
+                "model": model,
+                "genre": ga_pair['genre']['title'],
+                "audience": ga_pair['audience']['title'],
+                "error_type": type(general_error).__name__,
+                "error_message": str(general_error),
+                "traceback": traceback.format_exc()
+            }
+            error_filename = f"error_thinking_{genre_safe}_{audience_safe}_{timestamp}.json"
+            error_file_path = logs_dir / error_filename
+            with open(error_file_path, 'w', encoding='utf-8') as f:
+                json.dump(error_log, f, ensure_ascii=False, indent=2)
+            console.print(f"[dim]ã‚¨ãƒ©ãƒ¼ãƒ­ã‚°ã‚’ä¿å­˜: {error_filename}[/dim]")
+        
+        return []
+
+
diff --git a/easy_dataset_cli/xml_utils.py b/easy_dataset_cli/xml_utils.py
index ec5a370..4337616 100644
--- a/easy_dataset_cli/xml_utils.py
+++ b/easy_dataset_cli/xml_utils.py
@@ -5,6 +5,7 @@ import xml.etree.ElementTree as ET
 from xml.dom import minidom
 from collections import defaultdict
 from typing import List, Dict
+from pathlib import Path
 from rich.console import Console
 
 console = Console()
@@ -41,10 +42,10 @@ def parse_ga_from_text_fallback(content: str) -> List[Dict[str, Dict[str, str]]]
                         "description": audience_desc.strip()
                     }
                 })
-                console.print(f"[green]âœ“[/green] (æ‰‹å‹•è§£æ) {genre_title} x {audience_title}")
+                console.print(f"[green]âœ“[/green] (è‡ªå‹•è§£æ) {genre_title} x {audience_title}")
 
     except Exception as e:
-        console.print(f"[red]æ‰‹å‹•è§£æã‚‚å¤±æ•—:[/red] {e}")
+        console.print(f"[red]è‡ªå‹•è§£æã‚‚å¤±æ•—:[/red] {e}")
 
     return pairs
 
@@ -97,10 +98,10 @@ def parse_qa_from_text_fallback(content: str) -> List[Dict[str, str]]:
                     "question": question.strip(),
                     "answer": answer.strip()
                 })
-                console.print("[green]âœ“[/green] (æ‰‹å‹•è§£æ) Q&Aè¿½åŠ ")
+                console.print("[green]âœ“[/green] (è‡ªå‹•è§£æ) Q&Aè¿½åŠ ")
 
     except Exception as e:
-        console.print(f"[red]Q&Aæ‰‹å‹•è§£æã‚‚å¤±æ•—:[/red] {e}")
+        console.print(f"[red]Q&Aè‡ªå‹•è§£æã‚‚å¤±æ•—:[/red] {e}")
 
     return qa_pairs
 
@@ -123,15 +124,248 @@ def extract_simple_tag_content(content: str, tag: str) -> str:
         return ""
 
 
-def convert_to_xml_by_genre(all_qa_pairs: List[Dict[str, str]]) -> Dict[str, str]:
-    """Q&Aãƒšã‚¢ã®ãƒªã‚¹ãƒˆã‚’Genreã”ã¨ã«ã‚°ãƒ«ãƒ¼ãƒ—åŒ–ã—ã€æ•´å½¢ã•ã‚ŒãŸXMLæ–‡å­—åˆ—ã®è¾æ›¸ã«å¤‰æ›ã™ã‚‹"""
+def _parse_answer_with_think(answer_text: str) -> Dict[str, str]:
+    """<think>ã‚¿ã‚°ã‚’å«ã‚€å›ç­”ã‚’ãƒ‘ãƒ¼ã‚¹ã—ã¦åˆ†é›¢"""
+    import re
+    
+    # <think>...</think>ã‚¿ã‚°ã‚’æ¤œç´¢
+    think_match = re.search(r'<think>(.*?)</think>', answer_text, re.DOTALL)
+    
+    if think_match:
+        think_content = think_match.group(1).strip()
+        # <think>ã‚¿ã‚°ä»¥é™ã®å›ç­”ãƒ†ã‚­ã‚¹ãƒˆã‚’å–å¾—
+        answer_content = answer_text[think_match.end():].strip()
+        return {
+            "has_think": True,
+            "think_content": think_content,
+            "answer_content": answer_content
+        }
+    else:
+        return {
+            "has_think": False,
+            "think_content": "",
+            "answer_content": answer_text
+        }
+
+
+def load_existing_xml_file(xml_file_path: Path) -> List[Dict[str, str]]:
+    """æ—¢å­˜ã®XMLãƒ•ã‚¡ã‚¤ãƒ«ã‹ã‚‰Q&Aãƒšã‚¢ã‚’èª­ã¿è¾¼ã‚€"""
+    qa_pairs = []
+    
+    try:
+        if not xml_file_path.exists():
+            return qa_pairs
+            
+        tree = ET.parse(xml_file_path)
+        root = tree.getroot()
+        
+        genre = root.get('genre', 'Unknown')
+        
+        for pair in root.findall('Pair'):
+            audience_elem = pair.find('Audience')
+            question_elem = pair.find('Question')
+            answer_elem = pair.find('Answer')
+            
+            if all([audience_elem is not None, question_elem is not None, answer_elem is not None]):
+                qa_pairs.append({
+                    "genre": genre,
+                    "audience": audience_elem.text or "",
+                    "question": question_elem.text or "",
+                    "answer": answer_elem.text or ""
+                })
+                
+    except Exception as e:
+        console.print(f"[yellow]æ—¢å­˜XMLãƒ•ã‚¡ã‚¤ãƒ«ã®èª­ã¿è¾¼ã¿ã«å¤±æ•—: {e}[/yellow]")
+    
+    return qa_pairs
+
+
+def load_existing_xml_file_with_fallback(xml_file_path: Path, genre_from_filename: str = None) -> List[Dict[str, str]]:
+    """æ—¢å­˜ã®XMLãƒ•ã‚¡ã‚¤ãƒ«ã‹ã‚‰Q&Aãƒšã‚¢ã‚’èª­ã¿è¾¼ã¿ã€ãƒ•ã‚¡ã‚¤ãƒ«åã‹ã‚‰ã‚¸ãƒ£ãƒ³ãƒ«æƒ…å ±ã‚’å–å¾—ã™ã‚‹ãƒ•ã‚©ãƒ¼ãƒ«ãƒãƒƒã‚¯é–¢æ•°"""
+    qa_pairs = []
+    
+    try:
+        if not xml_file_path.exists():
+            return qa_pairs
+            
+        tree = ET.parse(xml_file_path)
+        root = tree.getroot()
+        
+        # XMLå†…ã®genreå±æ€§ã‚’å„ªå…ˆã—ã€ãªã‘ã‚Œã°ãƒ•ã‚¡ã‚¤ãƒ«åã‹ã‚‰å–å¾—ã—ãŸæƒ…å ±ã‚’ä½¿ç”¨
+        genre = root.get('genre', genre_from_filename or 'Unknown')
+        
+        for pair in root.findall('Pair'):
+            audience_elem = pair.find('Audience')
+            question_elem = pair.find('Question')
+            answer_elem = pair.find('Answer')
+            
+            # Audienceè¦ç´ ãŒãªã„å ´åˆã¯ã€ãƒ•ã‚¡ã‚¤ãƒ«åã‹ã‚‰å–å¾—ã—ãŸAudienceæƒ…å ±ã‚’ä½¿ç”¨
+            if audience_elem is None:
+                # ãƒ•ã‚¡ã‚¤ãƒ«åã‹ã‚‰Audienceæƒ…å ±ã‚’å–å¾—ï¼ˆã“ã®é–¢æ•°ã®å‘¼ã³å‡ºã—å…ƒã§è¨­å®šæ¸ˆã¿ï¼‰
+                audience = genre_from_filename.split('_')[-1] if genre_from_filename and '_' in genre_from_filename else ""
+            else:
+                audience = audience_elem.text or ""
+            
+            if question_elem is not None and answer_elem is not None:
+                qa_pairs.append({
+                    "genre": genre,
+                    "audience": audience,
+                    "question": question_elem.text or "",
+                    "answer": answer_elem.text or ""
+                })
+                
+    except Exception as e:
+        console.print(f"[yellow]æ—¢å­˜XMLãƒ•ã‚¡ã‚¤ãƒ«ã®èª­ã¿è¾¼ã¿ã«å¤±æ•—: {e}[/yellow]")
+    
+    return qa_pairs
+
+
+def aggregate_logs_xml_to_qa(logs_dir: Path, qa_dir: Path) -> None:
+    """logsãƒ•ã‚©ãƒ«ãƒ€å†…ã®XMLãƒ•ã‚¡ã‚¤ãƒ«ã‚’é›†ç´„ã—ã¦qaãƒ•ã‚©ãƒ«ãƒ€ã®æ—¢å­˜XMLãƒ•ã‚¡ã‚¤ãƒ«ã‚’æ›´æ–°ãƒ»è¿½åŠ ã™ã‚‹"""
+    from rich.console import Console
+    
+    console = Console()
+    
+    console.print(f"[bold blue]logsãƒ•ã‚©ãƒ«ãƒ€ã‹ã‚‰XMLãƒ•ã‚¡ã‚¤ãƒ«ã‚’é›†ç´„ã—ã¦æ—¢å­˜ãƒ•ã‚¡ã‚¤ãƒ«ã‚’æ›´æ–°ã—ã¦ã„ã¾ã™...[/bold blue]")
+    
+    # qaãƒ‡ã‚£ãƒ¬ã‚¯ãƒˆãƒªãŒå­˜åœ¨ã—ãªã„å ´åˆã¯ä½œæˆ
+    qa_dir.mkdir(parents=True, exist_ok=True)
+    
+    # logsãƒ‡ã‚£ãƒ¬ã‚¯ãƒˆãƒªå†…ã®XMLãƒ•ã‚¡ã‚¤ãƒ«ã‚’æ¤œç´¢
+    xml_files = list(logs_dir.glob("*.xml"))
+    
+    if not xml_files:
+        console.print(f"[yellow]logsãƒ•ã‚©ãƒ«ãƒ€ã«XMLãƒ•ã‚¡ã‚¤ãƒ«ãŒè¦‹ã¤ã‹ã‚Šã¾ã›ã‚“: {logs_dir}[/yellow]")
+        return
+    
+    console.print(f"[dim]{len(xml_files)}å€‹ã®XMLãƒ•ã‚¡ã‚¤ãƒ«ã‚’æ¤œå‡º[/dim]")
+    
+    # Genreã”ã¨ã«Q&Aãƒšã‚¢ã‚’é›†ç´„
+    genre_qa_pairs = defaultdict(list)
+    
+    for xml_file in xml_files:
+        try:
+            console.print(f"[dim]å‡¦ç†ä¸­: {xml_file.name}[/dim]")
+            
+            # ãƒ•ã‚¡ã‚¤ãƒ«åã‹ã‚‰Genreæƒ…å ±ã‚’æŠ½å‡ºï¼ˆä¾‹: qa_pairs_FAQ_åˆå¿ƒè€…ã‚²ãƒ¼ãƒãƒ¼_20250815_171008.xmlï¼‰
+            filename = xml_file.stem
+            if filename.startswith("qa_pairs_"):
+                # Genreã¨Audienceæƒ…å ±ã‚’æŠ½å‡º
+                parts = filename.replace("qa_pairs_", "").split("_")
+                if len(parts) >= 3:  # genre + audience + timestamp + timestamp
+                    genre = parts[0]
+                    # æ®‹ã‚Šã®éƒ¨åˆ†ã¯Audienceï¼ˆ_ã§åŒºåˆ‡ã‚‰ã‚Œã¦ã„ã‚‹å¯èƒ½æ€§ãŒã‚ã‚‹ï¼‰
+                    # æœ€å¾Œã®2è¦ç´ ã¯ã‚¿ã‚¤ãƒ ã‚¹ã‚¿ãƒ³ãƒ—ãªã®ã§é™¤å¤–
+                    audience = "_".join(parts[1:-2])
+                    
+                    console.print(f"[dim]ãƒ•ã‚¡ã‚¤ãƒ«åè§£æ: genre={genre}, audience={audience}[/dim]")
+                    
+                    # XMLãƒ•ã‚¡ã‚¤ãƒ«ã‹ã‚‰Q&Aãƒšã‚¢ã‚’èª­ã¿è¾¼ã‚€ï¼ˆãƒ•ã‚¡ã‚¤ãƒ«åã‹ã‚‰ã‚¸ãƒ£ãƒ³ãƒ«æƒ…å ±ã‚’æ¸¡ã™ï¼‰
+                    qa_pairs = load_existing_xml_file_with_fallback(xml_file, genre)
+                    
+                    console.print(f"[dim]èª­ã¿è¾¼ã‚“ã Q&Aãƒšã‚¢æ•°: {len(qa_pairs)}[/dim]")
+                    
+                    # Genreæƒ…å ±ã‚’ä»˜ä¸ã—ã¦ä¿å­˜
+                    for qa_pair in qa_pairs:
+                        qa_pair["genre"] = genre
+                        qa_pair["audience"] = audience
+                        genre_qa_pairs[genre].append(qa_pair)
+                else:
+                    console.print(f"[yellow]ãƒ•ã‚¡ã‚¤ãƒ«åã®è§£æã«å¤±æ•—: {filename}[/yellow]")
+                        
+        except Exception as e:
+            console.print(f"[yellow]ãƒ•ã‚¡ã‚¤ãƒ«ã®å‡¦ç†ä¸­ã«ã‚¨ãƒ©ãƒ¼: {xml_file.name} - {e}[/yellow]")
+            continue
+    
+    # Genreã”ã¨ã«æ—¢å­˜XMLãƒ•ã‚¡ã‚¤ãƒ«ã‚’æ›´æ–°
+    console.print(f"\n[bold green]é›†ç´„çµæœ:[/bold green]")
+    total_updated = 0
+    
+    for genre, qa_pairs in genre_qa_pairs.items():
+        console.print(f"  - [cyan]{genre}[/cyan]: {len(qa_pairs)}ä»¶ã®Q&Aã‚’è¿½åŠ ")
+        
+        # æ—¢å­˜ã®XMLãƒ•ã‚¡ã‚¤ãƒ«ã‚’æ¤œç´¢
+        safe_genre_name = "".join(c for c in genre if c.isalnum() or c in (' ', '_', '-')).strip().replace(' ', '_')
+        existing_file = qa_dir / f"{safe_genre_name}.xml"
+        
+        # æ—¢å­˜ã®Q&Aãƒšã‚¢ã‚’èª­ã¿è¾¼ã‚€ï¼ˆãƒ•ã‚¡ã‚¤ãƒ«ãŒå­˜åœ¨ã™ã‚‹å ´åˆï¼‰
+        existing_pairs = []
+        if existing_file.exists():
+            existing_pairs = load_existing_xml_file(existing_file)
+            console.print(f"    [dim]æ—¢å­˜ã®{len(existing_pairs)}ä»¶ã®Q&Aã‚’èª­ã¿è¾¼ã¿[/dim]")
+        
+        # æ–°ã—ã„Q&Aã‚’è¿½åŠ ï¼ˆé‡è¤‡ã‚’é¿ã‘ã‚‹ï¼‰
+        existing_questions = {pair["question"] for pair in existing_pairs}
+        new_pairs = []
+        for pair in qa_pairs:
+            if pair["question"] not in existing_questions:
+                new_pairs.append(pair)
+            else:
+                console.print(f"    [yellow]é‡è¤‡ã™ã‚‹Q&Aã‚’ã‚¹ã‚­ãƒƒãƒ—: {pair['question'][:50]}...[/yellow]")
+        
+        console.print(f"    [green]è¿½åŠ ã™ã‚‹æ–°ã—ã„Q&A: {len(new_pairs)}ä»¶[/green]")
+        
+        # æ—¢å­˜ã®ãƒšã‚¢ã«æ–°ã—ã„ãƒšã‚¢ã‚’è¿½åŠ 
+        updated_pairs = existing_pairs + new_pairs
+        
+        if updated_pairs:
+            # XMLã«å¤‰æ›
+            root = ET.Element("QAPairs")
+            root.set("genre", genre)
+
+            for item in updated_pairs:
+                pair_elem = ET.SubElement(root, "Pair")
+
+                audience_elem = ET.SubElement(pair_elem, "Audience")
+                audience_elem.text = item["audience"]
+
+                question_elem = ET.SubElement(pair_elem, "Question")
+                question_elem.text = item["question"]
+
+                answer_elem = ET.SubElement(pair_elem, "Answer")
+                answer_elem.text = item["answer"]
+
+            # æ•´å½¢ã—ã¦ä¿å­˜
+            rough_string = ET.tostring(root, 'utf-8')
+            reparsed = minidom.parseString(rough_string)
+            xml_content = reparsed.toprettyxml(indent="  ")
+            
+            existing_file.write_text(xml_content, encoding='utf-8')
+            console.print(f"    [green]âœ“[/green] {existing_file.name} ã‚’æ›´æ–° ({len(updated_pairs)}ä»¶)")
+            total_updated += 1
+        else:
+            console.print(f"    [yellow]æ›´æ–°ã™ã‚‹Q&AãŒã‚ã‚Šã¾ã›ã‚“[/yellow]")
+    
+    console.print(f"\n[bold green]âœ“[/bold green] åˆè¨ˆ{total_updated}å€‹ã®ã‚¸ãƒ£ãƒ³ãƒ«ã®XMLãƒ•ã‚¡ã‚¤ãƒ«ã‚’æ›´æ–°ã—ã¾ã—ãŸ")
+
+
+def convert_to_xml_by_genre(all_qa_pairs: List[Dict[str, str]], qa_dir: Path = None, append_mode: bool = False) -> Dict[str, str]:
+    """Q&Aãƒšã‚¢ã®ãƒªã‚¹ãƒˆã‚’Genreã”ã¨ã«ã‚°ãƒ«ãƒ¼ãƒ—åŒ–ã—ã€æ•´å½¢ã•ã‚ŒãŸXMLæ–‡å­—åˆ—ã®è¾æ›¸ã«å¤‰æ›ã™ã‚‹
+    
+    Args:
+        all_qa_pairs: å¤‰æ›ã™ã‚‹Q&Aãƒšã‚¢ã®ãƒªã‚¹ãƒˆ
+        qa_dir: QAãƒ•ã‚¡ã‚¤ãƒ«ãŒä¿å­˜ã•ã‚Œã¦ã„ã‚‹ãƒ‡ã‚£ãƒ¬ã‚¯ãƒˆãƒªï¼ˆè¿½åŠ ãƒ¢ãƒ¼ãƒ‰ã®å ´åˆã«å¿…è¦ï¼‰
+        append_mode: æ—¢å­˜ãƒ•ã‚¡ã‚¤ãƒ«ã«è¿½åŠ ã™ã‚‹ã‹ã©ã†ã‹
+    """
     grouped_by_genre = defaultdict(list)
 
     for item in all_qa_pairs:
         grouped_by_genre[item["genre"]].append(item)
 
     xml_outputs = {}
+    
     for genre, pairs in grouped_by_genre.items():
+        # è¿½åŠ ãƒ¢ãƒ¼ãƒ‰ã®å ´åˆã¯æ—¢å­˜ã®XMLãƒ•ã‚¡ã‚¤ãƒ«ã‚’èª­ã¿è¾¼ã‚€
+        if append_mode and qa_dir:
+            safe_genre_name = "".join(c for c in genre if c.isalnum() or c in (' ', '_', '-')).strip().replace(' ', '_')
+            existing_file = qa_dir / f"{safe_genre_name}.xml"
+            
+            if existing_file.exists():
+                existing_pairs = load_existing_xml_file(existing_file)
+                console.print(f"[dim]Genre '{genre}': æ—¢å­˜ã®{len(existing_pairs)}ä»¶ã®Q&Aã‚’èª­ã¿è¾¼ã¿ã¾ã—ãŸ[/dim]")
+                # æ—¢å­˜ã®ãƒšã‚¢ã‚’å…ˆé ­ã«è¿½åŠ 
+                pairs = existing_pairs + pairs
+        
         root = ET.Element("QAPairs")
         root.set("genre", genre)
 
@@ -145,10 +379,23 @@ def convert_to_xml_by_genre(all_qa_pairs: List[Dict[str, str]]) -> Dict[str, str
             question_elem.text = item["question"]
 
             answer_elem = ET.SubElement(pair_elem, "Answer")
-            answer_elem.text = item["answer"]
+            
+            # å›ç­”å†…å®¹ã‚’è§£æ
+            parsed_answer = _parse_answer_with_think(item["answer"])
+            
+            if parsed_answer["has_think"]:
+                # <think>ã‚’ã‚µãƒ–ã‚¨ãƒ¬ãƒ¡ãƒ³ãƒˆã¨ã—ã¦è¿½åŠ 
+                think_elem = ET.SubElement(answer_elem, "think")
+                think_elem.text = parsed_answer["think_content"]
+                think_elem.tail = parsed_answer["answer_content"]
+            else:
+                # é€šå¸¸ã®å›ç­”
+                answer_elem.text = parsed_answer["answer_content"]
 
         rough_string = ET.tostring(root, 'utf-8')
         reparsed = minidom.parseString(rough_string)
-        xml_outputs[genre] = reparsed.toprettyxml(indent="  ")
+        xml_output = reparsed.toprettyxml(indent="  ")
+        
+        xml_outputs[genre] = xml_output
 
     return xml_outputs
diff --git a/example/scripts/orin.bat b/example/scripts/orin.bat
new file mode 100644
index 0000000..cb3391b
--- /dev/null
+++ b/example/scripts/orin.bat
@@ -0,0 +1,5 @@
+uv run easy-dataset create-ga .\example\input\documents\Touhou_Chireiden.md --output-dir .\example\output\Touhou_Chireiden --num-ga-pairs 10
+
+uv run easy-dataset generate .\example\input\documents\Touhou_Chireiden.md  --ga-file .\example\output\Touhou_Chireiden\ga\ga_definitions.xml --output-dir .\example\output\Touhou_Chireiden\ --chunk-size 3000 --use-fulltext --append
+
+uv run easy-dataset convert-to-alpaca .\example\output\Touhou_Chireiden\qa --output-file example\output\Touhou_Chireiden\dataset.json --upload-hf --hf-repo-name MakiAi/Orin-Instruct-Alpaca-JP-v7
diff --git a/example/scripts/simple.bat b/example/scripts/simple.bat
new file mode 100644
index 0000000..15240c4
--- /dev/null
+++ b/example/scripts/simple.bat
@@ -0,0 +1 @@
+uv run easy-dataset generate .\example\input\documents\sample_document.txt  --ga-file .\example\output\sample_document\ga\ga_definitions.xml  --output-dir .\example\output\sample_document\ --use-thinking --append
diff --git a/fix_xml_generation.py b/fix_xml_generation.py
new file mode 100644
index 0000000..ebe1b4b
--- /dev/null
+++ b/fix_xml_generation.py
@@ -0,0 +1,34 @@
+#!/usr/bin/env python3
+"""Q&Aã‚¸ã‚§ãƒãƒ¬ãƒ¼ã‚¿ãƒ¼ã®ã‚·ã‚¹ãƒ†ãƒ ãƒ¡ãƒƒã‚»ãƒ¼ã‚¸ã‚’ä¿®æ­£ã™ã‚‹ã‚¹ã‚¯ãƒªãƒ—ãƒˆ"""
+
+import sys
+import os
+
+def fix_system_messages():
+    """qa_generator.pyã®ã‚·ã‚¹ãƒ†ãƒ ãƒ¡ãƒƒã‚»ãƒ¼ã‚¸ã‚’ä¿®æ­£"""
+    file_path = "c:/Prj/easy-dataset-cli/easy_dataset_cli/qa_generator.py"
+    
+    with open(file_path, 'r', encoding='utf-8') as f:
+        content = f.read()
+    
+    # å¤ã„ã‚·ã‚¹ãƒ†ãƒ ãƒ¡ãƒƒã‚»ãƒ¼ã‚¸ã‚’æ–°ã—ã„ã‚‚ã®ã«ç½®æ›
+    old_message = '"ã‚ãªãŸã¯ã€XMLå½¢å¼ã§å³å¯†ã«å‡ºåŠ›ã™ã‚‹å„ªç§€ãªã‚¢ã‚·ã‚¹ã‚¿ãƒ³ãƒˆã§ã™ã€‚XMLã®ç‰¹æ®Šæ–‡å­—ï¼ˆ&, <, >, \\", \'ï¼‰ã¯é©åˆ‡ã«ã‚¨ã‚¹ã‚±ãƒ¼ãƒ—ã—ã€æ”¹è¡Œã¯å«ã‚ãšã«å‡ºåŠ›ã—ã¦ãã ã•ã„ã€‚"'
+    new_message = '"ã‚ãªãŸã¯ã€XMLå½¢å¼ã§å³å¯†ã«å‡ºåŠ›ã™ã‚‹å„ªç§€ãªã‚¢ã‚·ã‚¹ã‚¿ãƒ³ãƒˆã§ã™ã€‚é€šå¸¸ã®XMLã®ç‰¹æ®Šæ–‡å­—ï¼ˆ&, \\", \'ï¼‰ã¯é©åˆ‡ã«ã‚¨ã‚¹ã‚±ãƒ¼ãƒ—ã—ã¦ãã ã•ã„ã€‚ãŸã ã—ã€<Question>ã€<Answer>ã€<think>ã‚¿ã‚°ã¯ãã®ã¾ã¾ä½¿ç”¨ã—ã¦ãã ã•ã„ã€‚æ”¹è¡Œã¯å«ã‚ãšã«å‡ºåŠ›ã—ã¦ãã ã•ã„ã€‚"'
+    
+    # ç½®æ›å®Ÿè¡Œ
+    new_content = content.replace(old_message, new_message)
+    
+    # æ€è€ƒãƒ•ãƒ­ãƒ¼ç”¨ã®ãƒ¡ãƒƒã‚»ãƒ¼ã‚¸ã‚‚çµ±ä¸€
+    thinking_old = '"ã‚ãªãŸã¯ã€XMLå½¢å¼ã§å‡ºåŠ›ã™ã‚‹å„ªç§€ãªã‚¢ã‚·ã‚¹ã‚¿ãƒ³ãƒˆã§ã™ã€‚<think>ã‚¿ã‚°ã¯ç‰¹åˆ¥ãªã‚¿ã‚°ãªã®ã§ã‚¨ã‚¹ã‚±ãƒ¼ãƒ—ã—ãªã„ã§ãã ã•ã„ã€‚ãã‚Œä»¥å¤–ã®XMLã®ç‰¹æ®Šæ–‡å­—ï¼ˆ&, <, >, \\", \'ï¼‰ã¯é©åˆ‡ã«ã‚¨ã‚¹ã‚±ãƒ¼ãƒ—ã—ã€æ”¹è¡Œã¯å«ã‚ãšã«å‡ºåŠ›ã—ã¦ãã ã•ã„ã€‚"'
+    new_content = new_content.replace(thinking_old, new_message)
+    
+    # ãƒ•ã‚¡ã‚¤ãƒ«ã«æ›¸ãæˆ»ã—
+    with open(file_path, 'w', encoding='utf-8') as f:
+        f.write(new_content)
+    
+    print(f"ä¿®æ­£å®Œäº†: {file_path}")
+    print(f"ç½®æ›å›æ•° (é€šå¸¸): {content.count(old_message)}")
+    print(f"ç½®æ›å›æ•° (æ€è€ƒ): {content.count(thinking_old)}")
+
+if __name__ == "__main__":
+    fix_system_messages()
diff --git a/tests/test_aggregate_logs.py b/tests/test_aggregate_logs.py
new file mode 100644
index 0000000..6f1c10f
--- /dev/null
+++ b/tests/test_aggregate_logs.py
@@ -0,0 +1,145 @@
+#!/usr/bin/env python3
+"""logsãƒ•ã‚©ãƒ«ãƒ€ã®XMLé›†ç´„æ©Ÿèƒ½ã®ãƒ†ã‚¹ãƒˆã‚¹ã‚¯ãƒªãƒ—ãƒˆ"""
+
+import sys
+import os
+import tempfile
+import shutil
+from pathlib import Path
+sys.path.append(os.path.join(os.path.dirname(__file__), 'easy_dataset_cli'))
+
+from easy_dataset_cli.xml_utils import aggregate_logs_xml_to_qa, load_existing_xml_file
+from easy_dataset_cli.core import aggregate_logs_xml_to_qa as core_aggregate_logs_xml_to_qa
+from rich.console import Console
+
+console = Console()
+
+def create_test_xml_files(logs_dir: Path):
+    """ãƒ†ã‚¹ãƒˆç”¨ã®XMLãƒ•ã‚¡ã‚¤ãƒ«ã‚’ä½œæˆ"""
+    
+    # logsãƒ‡ã‚£ãƒ¬ã‚¯ãƒˆãƒªã‚’ä½œæˆ
+    logs_dir.mkdir(parents=True, exist_ok=True)
+    
+    # ãƒ†ã‚¹ãƒˆç”¨XMLãƒ•ã‚¡ã‚¤ãƒ«1: FAQ_åˆå¿ƒè€…ã‚²ãƒ¼ãƒãƒ¼
+    faq_xml_content = '''<?xml version="1.0" ?>
+<QAPairs genre="FAQ">
+  <Pair>
+    <Audience>åˆå¿ƒè€…ã‚²ãƒ¼ãƒãƒ¼</Audience>
+    <Question>æ±æ–¹Projectã¨ã¯ä½•ã§ã™ã‹ï¼Ÿ</Question>
+    <Answer>æ±æ–¹Projectã¯ã€ä¸Šæµ·ã‚¢ãƒªã‚¹å¹»æ¨‚å›£ã«ã‚ˆã£ã¦åˆ¶ä½œã•ã‚ŒãŸå¼¾å¹•ç³»ã‚·ãƒ¥ãƒ¼ãƒ†ã‚£ãƒ³ã‚°ã‚²ãƒ¼ãƒ ã‚·ãƒªãƒ¼ã‚ºã§ã™ã€‚</Answer>
+  </Pair>
+  <Pair>
+    <Audience>åˆå¿ƒè€…ã‚²ãƒ¼ãƒãƒ¼</Audience>
+    <Question>æœ€åˆã«ã©ã®ã‚²ãƒ¼ãƒ ã‚’ãƒ—ãƒ¬ã‚¤ã™ã‚Œã°ã„ã„ã§ã™ã‹ï¼Ÿ</Question>
+    <Answer>åˆå¿ƒè€…ã«ã¯ã€Œæ±æ–¹ç´…é­”éƒ·ã€ã‚„ã€Œæ±æ–¹å¦–ã€…å¤¢ã€ãŒãŠã™ã™ã‚ã§ã™ã€‚</Answer>
+  </Pair>
+</QAPairs>'''
+    
+    faq_file = logs_dir / "qa_pairs_FAQ_åˆå¿ƒè€…ã‚²ãƒ¼ãƒãƒ¼_20250815_171008.xml"
+    faq_file.write_text(faq_xml_content, encoding='utf-8')
+    
+    # ãƒ†ã‚¹ãƒˆç”¨XMLãƒ•ã‚¡ã‚¤ãƒ«2: ãƒ†ã‚¯ãƒ‹ã‚«ãƒ«ã‚¬ã‚¤ãƒ‰_PCã‚²ãƒ¼ãƒŸãƒ³ã‚°æ„›å¥½è€…
+    tech_xml_content = '''<?xml version="1.0" ?>
+<QAPairs genre="ãƒ†ã‚¯ãƒ‹ã‚«ãƒ«ã‚¬ã‚¤ãƒ‰">
+  <Pair>
+    <Audience>PCã‚²ãƒ¼ãƒŸãƒ³ã‚°æ„›å¥½è€…</Audience>
+    <Question>æ±æ–¹Projectã®ã‚·ã‚¹ãƒ†ãƒ è¦ä»¶ã¯ï¼Ÿ</Question>
+    <Answer>æ±æ–¹Projectã®ã‚²ãƒ¼ãƒ ã¯æ¯”è¼ƒçš„å¤ã„PCã§ã‚‚å‹•ä½œã™ã‚‹ã‚ˆã†ã«è¨­è¨ˆã•ã‚Œã¦ã„ã¾ã™ã€‚</Answer>
+  </Pair>
+  <Pair>
+    <Audience>PCã‚²ãƒ¼ãƒŸãƒ³ã‚°æ„›å¥½è€…</Audience>
+    <Question>Steamç‰ˆã¨ãƒ€ã‚¦ãƒ³ãƒ­ãƒ¼ãƒ‰ç‰ˆã®é•ã„ã¯ï¼Ÿ</Question>
+    <Answer>Steamç‰ˆã¯è‡ªå‹•ã‚¢ãƒƒãƒ—ãƒ‡ãƒ¼ãƒˆæ©Ÿèƒ½ãŒã‚ã‚Šã€ã‚¯ãƒ©ã‚¦ãƒ‰ã‚»ãƒ¼ãƒ–ã«å¯¾å¿œã—ã¦ã„ã¾ã™ã€‚</Answer>
+  </Pair>
+</QAPairs>'''
+    
+    tech_file = logs_dir / "qa_pairs_ãƒ†ã‚¯ãƒ‹ã‚«ãƒ«ã‚¬ã‚¤ãƒ‰_PCã‚²ãƒ¼ãƒŸãƒ³ã‚°æ„›å¥½è€…_20250815_171009.xml"
+    tech_file.write_text(tech_xml_content, encoding='utf-8')
+    
+    # ãƒ†ã‚¹ãƒˆç”¨XMLãƒ•ã‚¡ã‚¤ãƒ«3: FAQ_ä¸Šç´šè€…
+    faq_advanced_xml_content = '''<?xml version="1.0" ?>
+<QAPairs genre="FAQ">
+  <Pair>
+    <Audience>ä¸Šç´šè€…</Audience>
+    <Question>æ±æ–¹Projectã®ã‚­ãƒ£ãƒ©ã‚¯ã‚¿ãƒ¼è¨­å®šã¯ã©ã“ã§ç¢ºèªã§ãã¾ã™ã‹ï¼Ÿ</Question>
+    <Answer>å…¬å¼ã‚µã‚¤ãƒˆã‚„å„ã‚²ãƒ¼ãƒ ã®ãƒãƒ‹ãƒ¥ã‚¢ãƒ«ã€äºŒæ¬¡å‰µä½œæƒ…å ±ã‚µã‚¤ãƒˆã§è©³ç´°ãªè¨­å®šã‚’ç¢ºèªã§ãã¾ã™ã€‚</Answer>
+  </Pair>
+  <Pair>
+    <Audience>ä¸Šç´šè€…</Audience>
+    <Question>å¼¾å¹•ã®é›£æ˜“åº¦è¨­å®šã«ã¤ã„ã¦æ•™ãˆã¦ãã ã•ã„ã€‚</Question>
+    <Answer>å„ã‚²ãƒ¼ãƒ ã«ã¯è¤‡æ•°ã®é›£æ˜“åº¦è¨­å®šãŒã‚ã‚Šã€ç‰¹ã«ã€ŒExtraã€ã‚„'Phantasm'ã¯éå¸¸ã«é«˜ã„é›£æ˜“åº¦ã§ã™ã€‚</Answer>
+  </Pair>
+</QAPairs>'''
+    
+    faq_advanced_file = logs_dir / "qa_pairs_FAQ_ä¸Šç´šè€…_20250815_171010.xml"
+    faq_advanced_file.write_text(faq_advanced_xml_content, encoding='utf-8')
+
+def test_aggregate_logs():
+    """logsãƒ•ã‚©ãƒ«ãƒ€ã®XMLé›†ç´„æ©Ÿèƒ½ã®ãƒ†ã‚¹ãƒˆ"""
+    
+    print("=== logsãƒ•ã‚©ãƒ«ãƒ€ã®XMLé›†ç´„æ©Ÿèƒ½ãƒ†ã‚¹ãƒˆ ===\n")
+    
+    # ä¸€æ™‚ãƒ‡ã‚£ãƒ¬ã‚¯ãƒˆãƒªã‚’ä½œæˆ
+    with tempfile.TemporaryDirectory() as temp_dir:
+        temp_path = Path(temp_dir)
+        logs_dir = temp_path / "logs"
+        qa_dir = temp_path / "qa"
+        
+        # ãƒ†ã‚¹ãƒˆç”¨XMLãƒ•ã‚¡ã‚¤ãƒ«ã‚’ä½œæˆ
+        create_test_xml_files(logs_dir)
+        
+        console.print(f"ãƒ†ã‚¹ãƒˆç”¨logsãƒ‡ã‚£ãƒ¬ã‚¯ãƒˆãƒª: {logs_dir}")
+        console.print(f"ãƒ†ã‚¹ãƒˆç”¨qaãƒ‡ã‚£ãƒ¬ã‚¯ãƒˆãƒª: {qa_dir}")
+        
+        # XMLãƒ•ã‚¡ã‚¤ãƒ«ã‚’é›†ç´„
+        console.print("\n[bold blue]XMLãƒ•ã‚¡ã‚¤ãƒ«ã‚’é›†ç´„ä¸­...[/bold blue]")
+        aggregate_logs_xml_to_qa(logs_dir, qa_dir)
+        
+        # çµæœã‚’ç¢ºèª
+        console.print("\n[bold green]=== é›†ç´„çµæœ ===[/bold green]")
+        
+        # qaãƒ‡ã‚£ãƒ¬ã‚¯ãƒˆãƒªå†…ã®ãƒ•ã‚¡ã‚¤ãƒ«ã‚’ç¢ºèª
+        xml_files = list(qa_dir.glob("*.xml"))
+        console.print(f"ç”Ÿæˆã•ã‚ŒãŸXMLãƒ•ã‚¡ã‚¤ãƒ«æ•°: {len(xml_files)}")
+        
+        for xml_file in xml_files:
+            console.print(f"\n[cyan]{xml_file.name}[/cyan]:")
+            
+            # XMLãƒ•ã‚¡ã‚¤ãƒ«ã®å†…å®¹ã‚’ç¢ºèª
+            qa_pairs = load_existing_xml_file(xml_file)
+            console.print(f"  Q&Aãƒšã‚¢æ•°: {len(qa_pairs)}")
+            
+            for i, qa in enumerate(qa_pairs, 1):
+                console.print(f"  {i}. [yellow]è³ªå•:[/yellow] {qa['question']}")
+                console.print(f"     [yellow]å›ç­”:[/yellow] {qa['answer']}")
+                console.print(f"     [dim]ã‚¸ãƒ£ãƒ³ãƒ«:[/dim] {qa['genre']}")
+                console.print(f"     [dim]å¯¾è±¡èª­è€…:[/dim] {qa['audience']}")
+        
+        # æœŸå¾…ã•ã‚Œã‚‹çµæœã‚’ç¢ºèª
+        expected_files = ["FAQ.xml", "ãƒ†ã‚¯ãƒ‹ã‚«ãƒ«ã‚¬ã‚¤ãƒ‰.xml"]
+        console.print(f"\n[bold blue]=== æœŸå¾…ã•ã‚Œã‚‹ãƒ•ã‚¡ã‚¤ãƒ« ===[/bold blue]")
+        for expected_file in expected_files:
+            expected_path = qa_dir / expected_file
+            if expected_path.exists():
+                console.print(f"[green]âœ“[/green] {expected_file} ãŒç”Ÿæˆã•ã‚Œã¾ã—ãŸ")
+            else:
+                console.print(f"[red]âœ—[/red] {expected_file} ãŒç”Ÿæˆã•ã‚Œã¦ã„ã¾ã›ã‚“")
+        
+        # FAQ.xmlã®å†…å®¹ã‚’è©³ç´°ã«ç¢ºèª
+        faq_file = qa_dir / "FAQ.xml"
+        if faq_file.exists():
+            console.print(f"\n[bold blue]=== FAQ.xmlã®è©³ç´°ç¢ºèª ===[/bold blue]")
+            faq_content = faq_file.read_text(encoding='utf-8')
+            console.print(faq_content)
+        
+        # ãƒ†ã‚¹ãƒˆçµæœã‚’è¿”ã™
+        success = len(xml_files) == 2 and all((qa_dir / f).exists() for f in expected_files)
+        return success
+
+if __name__ == "__main__":
+    success = test_aggregate_logs()
+    if success:
+        console.print("\nâœ… ã™ã¹ã¦ã®ãƒ†ã‚¹ãƒˆãŒæˆåŠŸã—ã¾ã—ãŸï¼")
+    else:
+        console.print("\nâŒ ãƒ†ã‚¹ãƒˆã«å¤±æ•—ã—ã¾ã—ãŸã€‚")
+    sys.exit(0 if success else 1)
diff --git a/tests/test_answer_extraction.py b/tests/test_answer_extraction.py
new file mode 100644
index 0000000..8d96d67
--- /dev/null
+++ b/tests/test_answer_extraction.py
@@ -0,0 +1,56 @@
+#!/usr/bin/env python3
+"""Answerè¦ç´ ã®å†…å®¹å–å¾—ãƒ†ã‚¹ãƒˆ"""
+
+import xml.etree.ElementTree as ET
+
+def test_answer_content_extraction():
+    """Answerè¦ç´ ã®å†…å®¹å–å¾—ã‚’ãƒ†ã‚¹ãƒˆ"""
+    
+    # ãƒ†ã‚¹ãƒˆXML
+    xml_content = """<QAPairs>
+    <Pair>
+        <Question>ãƒ†ã‚¹ãƒˆè³ªå•1</Question>
+        <Answer><think>æ€è€ƒãƒ—ãƒ­ã‚»ã‚¹</think>å›ç­”å†…å®¹</Answer>
+    </Pair>
+    <Pair>
+        <Question>ãƒ†ã‚¹ãƒˆè³ªå•2</Question>
+        <Answer>æ™®é€šã®å›ç­”</Answer>
+    </Pair>
+</QAPairs>"""
+    
+    root = ET.fromstring(xml_content)
+    
+    for pair_node in root.findall('Pair'):
+        question_node = pair_node.find('Question')
+        answer_node = pair_node.find('Answer')
+        
+        if question_node is not None and answer_node is not None:
+            question_text = question_node.text or ""
+            
+            print(f"è³ªå•: {question_text}")
+            print(f"Answerè¦ç´ ã®å­è¦ç´ æ•°: {len(answer_node)}")
+            print(f"Answer.text: '{answer_node.text}'")
+            print(f"Answer.tail: '{answer_node.tail}'")
+            
+            # ã‚µãƒ–ã‚¨ãƒ¬ãƒ¡ãƒ³ãƒˆãŒã‚ã‚‹å ´åˆã®è©³ç´°ç¢ºèª
+            if len(answer_node) > 0:
+                for i, child in enumerate(answer_node):
+                    print(f"  å­è¦ç´ {i}: tag='{child.tag}', text='{child.text}', tail='{child.tail}'")
+            
+            # <Answer>è¦ç´ å†…ã®å…¨ã¦ã®å†…å®¹ã‚’å–å¾—ï¼ˆã‚µãƒ–ã‚¨ãƒ¬ãƒ¡ãƒ³ãƒˆå«ã‚€ï¼‰
+            if len(answer_node) > 0:
+                # ã‚µãƒ–ã‚¨ãƒ¬ãƒ¡ãƒ³ãƒˆãŒã‚ã‚‹å ´åˆã€XMLæ–‡å­—åˆ—ã¨ã—ã¦å†æ§‹ç¯‰
+                answer_content = ET.tostring(answer_node, encoding='unicode', method='xml')
+                print(f"Answer XML: {answer_content}")
+                # <Answer>ã‚¿ã‚°ã‚’é™¤å»ã—ã¦å†…å®¹ã®ã¿å–å¾—
+                answer_text = answer_content[answer_content.find('>')+1:answer_content.rfind('<')]
+                print(f"æŠ½å‡ºã•ã‚ŒãŸå†…å®¹: '{answer_text}'")
+            else:
+                # ã‚µãƒ–ã‚¨ãƒ¬ãƒ¡ãƒ³ãƒˆãŒãªã„å ´åˆã¯é€šå¸¸ã®ãƒ†ã‚­ã‚¹ãƒˆ
+                answer_text = answer_node.text or ""
+                print(f"é€šå¸¸ãƒ†ã‚­ã‚¹ãƒˆ: '{answer_text}'")
+            
+            print("---")
+
+if __name__ == "__main__":
+    test_answer_content_extraction()
diff --git a/tests/test_fixed_parsing.py b/tests/test_fixed_parsing.py
new file mode 100644
index 0000000..f0104f2
--- /dev/null
+++ b/tests/test_fixed_parsing.py
@@ -0,0 +1,68 @@
+#!/usr/bin/env python3
+"""ä¿®æ­£ã•ã‚ŒãŸAnswerè§£æã®ãƒ†ã‚¹ãƒˆ"""
+
+import xml.etree.ElementTree as ET
+
+def test_fixed_answer_parsing():
+    """ä¿®æ­£ã•ã‚ŒãŸAnswerè§£æã‚’ãƒ†ã‚¹ãƒˆ"""
+    
+    # ãƒ†ã‚¹ãƒˆXMLï¼ˆå®Ÿéš›ã®ãƒ•ã‚¡ã‚¤ãƒ«ã¨åŒã˜æ§‹é€ ï¼‰
+    xml_content = """<QAPairs>
+    <Pair>
+        <Question>ãƒ†ã‚¹ãƒˆè³ªå•1</Question>
+        <Answer>
+            <think>ã“ã‚Œã¯æ€è€ƒãƒ—ãƒ­ã‚»ã‚¹ã§ã™</think>
+            ã“ã‚Œã¯å›ç­”å†…å®¹ã§ã™ã€‚
+        </Answer>
+    </Pair>
+    <Pair>
+        <Question>ãƒ†ã‚¹ãƒˆè³ªå•2</Question>
+        <Answer>æ™®é€šã®å›ç­”ã§ã™ã€‚</Answer>
+    </Pair>
+</QAPairs>"""
+    
+    root = ET.fromstring(xml_content)
+    
+    for i, pair_node in enumerate(root.findall('Pair'), 1):
+        question_node = pair_node.find('Question')
+        answer_node = pair_node.find('Answer')
+        
+        if question_node is not None and answer_node is not None:
+            question_text = question_node.text or ""
+            
+            print(f"=== Pair {i} ===")
+            print(f"è³ªå•: {question_text.strip()}")
+            print(f"Answerè¦ç´ ã®å­è¦ç´ æ•°: {len(answer_node)}")
+            
+            # <Answer>è¦ç´ å†…ã®å†…å®¹ã‚’é©åˆ‡ã«å–å¾—
+            if len(answer_node) > 0:
+                # ã‚µãƒ–ã‚¨ãƒ¬ãƒ¡ãƒ³ãƒˆãŒã‚ã‚‹å ´åˆï¼ˆ<think>ã‚¿ã‚°ãªã©ï¼‰
+                answer_parts = []
+                
+                # Answerè¦ç´ ã®ç›´æ¥ã®ãƒ†ã‚­ã‚¹ãƒˆï¼ˆ<think>ã‚ˆã‚Šå‰ï¼‰
+                if answer_node.text:
+                    answer_parts.append(answer_node.text.strip())
+                    print(f"Answer.text: '{answer_node.text.strip()}'")
+                
+                # å„ã‚µãƒ–ã‚¨ãƒ¬ãƒ¡ãƒ³ãƒˆã®tailï¼ˆã‚µãƒ–ã‚¨ãƒ¬ãƒ¡ãƒ³ãƒˆã®å¾Œã®ãƒ†ã‚­ã‚¹ãƒˆï¼‰
+                for child in answer_node:
+                    print(f"å­è¦ç´ : tag='{child.tag}', text='{child.text}', tail='{child.tail}'")
+                    if child.tag == 'think':
+                        # <think>ã‚¿ã‚°ã®å†…å®¹ã‚’å–å¾—
+                        think_content = child.text or ""
+                        answer_parts.append(f"<think>{think_content}</think>")
+                    
+                    # ã‚µãƒ–ã‚¨ãƒ¬ãƒ¡ãƒ³ãƒˆã®å¾Œã®ãƒ†ã‚­ã‚¹ãƒˆ
+                    if child.tail:
+                        answer_parts.append(child.tail.strip())
+                
+                answer_text = "".join(answer_parts)
+            else:
+                # ã‚µãƒ–ã‚¨ãƒ¬ãƒ¡ãƒ³ãƒˆãŒãªã„å ´åˆã¯é€šå¸¸ã®ãƒ†ã‚­ã‚¹ãƒˆ
+                answer_text = answer_node.text or ""
+            
+            print(f"æœ€çµ‚çš„ãªå›ç­”: '{answer_text}'")
+            print()
+
+if __name__ == "__main__":
+    test_fixed_answer_parsing()
diff --git a/tests/test_simple_xml.py b/tests/test_simple_xml.py
new file mode 100644
index 0000000..ec2d59e
--- /dev/null
+++ b/tests/test_simple_xml.py
@@ -0,0 +1,68 @@
+#!/usr/bin/env python3
+"""ElementTreeã§thinkã‚¿ã‚°ã‚’ä¿æŒã™ã‚‹ãƒ†ã‚¹ãƒˆ"""
+
+def test_elementtree_with_cdata():
+    """ElementTreeã§CDATAã‚»ã‚¯ã‚·ãƒ§ãƒ³ã‚’ä½¿ã£ã¦thinkã‚¿ã‚°ã‚’ä¿æŒ"""
+    
+    import xml.etree.ElementTree as ET
+    from xml.dom import minidom
+    
+    # ã‚µãƒ³ãƒ—ãƒ«ãƒ‡ãƒ¼ã‚¿
+    qa_pairs = [
+        {
+            "question": "ãƒ†ã‚¹ãƒˆè³ªå•1",
+            "answer": "<think>ã“ã‚Œã¯æ€è€ƒãƒ—ãƒ­ã‚»ã‚¹ã§ã™</think>ã“ã‚Œã¯ãƒ†ã‚¹ãƒˆå›ç­”1ã§ã™ã€‚"
+        },
+        {
+            "question": "ãƒ†ã‚¹ãƒˆè³ªå•2", 
+            "answer": "<think>åˆ¥ã®æ€è€ƒãƒ—ãƒ­ã‚»ã‚¹</think>ã“ã‚Œã¯ãƒ†ã‚¹ãƒˆå›ç­”2ã§ã™ã€‚"
+        }
+    ]
+    
+    print("æ–¹æ³•1: å˜ç´”ãªæ–‡å­—åˆ—ç½®æ›")
+    # æ–¹æ³•1: ElementTreeã§ç”Ÿæˆå¾Œã€æ–‡å­—åˆ—ç½®æ›
+    root = ET.Element("QAPairs")
+    for qa in qa_pairs:
+        pair_elem = ET.SubElement(root, "Pair")
+        question_elem = ET.SubElement(pair_elem, "Question")
+        question_elem.text = qa["question"]
+        answer_elem = ET.SubElement(pair_elem, "Answer")
+        answer_elem.text = qa["answer"]
+    
+    # æ•´å½¢
+    rough_string = ET.tostring(root, 'utf-8')
+    reparsed = minidom.parseString(rough_string)
+    pretty_xml = reparsed.toprettyxml(indent="  ")
+    
+    # å˜ç´”ãªç½®æ›ã§thinkã‚¿ã‚°ã‚’å¾©å…ƒ
+    pretty_xml = pretty_xml.replace("&lt;think&gt;", "<think>")
+    pretty_xml = pretty_xml.replace("&lt;/think&gt;", "</think>")
+    
+    print(pretty_xml)
+    
+    print("\næ–¹æ³•2: ET.toustringå¾Œã«ç½®æ›")
+    # æ–¹æ³•2: ET.tostringã®çµæœã‚’ç›´æ¥æ“ä½œ
+    xml_string = ET.tostring(root, encoding='unicode')
+    xml_string = xml_string.replace("&lt;think&gt;", "<think>")
+    xml_string = xml_string.replace("&lt;/think&gt;", "</think>")
+    
+    # æ‰‹å‹•ã§æ•´å½¢
+    import xml.dom.minidom
+    dom = xml.dom.minidom.parseString(xml_string)
+    pretty_xml2 = dom.toprettyxml(indent="  ")
+    
+    print(pretty_xml2)
+    
+    # <think>ã‚¿ã‚°ãŒã‚¨ã‚¹ã‚±ãƒ¼ãƒ—ã•ã‚Œã¦ã„ã‚‹ã‹ãƒã‚§ãƒƒã‚¯
+    if "&lt;think&gt;" in pretty_xml:
+        print("âŒ æ–¹æ³•1: <think>ã‚¿ã‚°ãŒã‚¨ã‚¹ã‚±ãƒ¼ãƒ—ã•ã‚Œã¦ã„ã¾ã™!")
+    else:
+        print("âœ… æ–¹æ³•1: <think>ã‚¿ã‚°ã¯ã‚¨ã‚¹ã‚±ãƒ¼ãƒ—ã•ã‚Œã¦ã„ã¾ã›ã‚“!")
+        
+    if "&lt;think&gt;" in pretty_xml2:
+        print("âŒ æ–¹æ³•2: <think>ã‚¿ã‚°ãŒã‚¨ã‚¹ã‚±ãƒ¼ãƒ—ã•ã‚Œã¦ã„ã¾ã™!")
+    else:
+        print("âœ… æ–¹æ³•2: <think>ã‚¿ã‚°ã¯ã‚¨ã‚¹ã‚±ãƒ¼ãƒ—ã•ã‚Œã¦ã„ã¾ã›ã‚“!")
+
+if __name__ == "__main__":
+    test_elementtree_with_cdata()
diff --git a/tests/test_subelement.py b/tests/test_subelement.py
new file mode 100644
index 0000000..2c4bad0
--- /dev/null
+++ b/tests/test_subelement.py
@@ -0,0 +1,59 @@
+#!/usr/bin/env python3
+"""ã‚µãƒ–ã‚¨ãƒ¬ãƒ¡ãƒ³ãƒˆã§thinkã‚¿ã‚°ã‚’æ‰±ã†ãƒ†ã‚¹ãƒˆ"""
+
+import sys
+import os
+sys.path.insert(0, os.path.dirname(os.path.abspath(__file__)))
+
+from easy_dataset_cli.qa_generator import _parse_answer_with_think, _save_qa_pairs_to_xml
+from pathlib import Path
+
+def test_parse_answer_with_think():
+    """_parse_answer_with_thinké–¢æ•°ã®ãƒ†ã‚¹ãƒˆ"""
+    
+    # ãƒ†ã‚¹ãƒˆã‚±ãƒ¼ã‚¹1: <think>ã‚¿ã‚°ã‚ã‚Š
+    answer1 = "<think>ã“ã‚Œã¯æ€è€ƒãƒ—ãƒ­ã‚»ã‚¹ã§ã™</think>ã“ã‚Œã¯ãƒ†ã‚¹ãƒˆå›ç­”1ã§ã™ã€‚"
+    result1 = _parse_answer_with_think(answer1)
+    print("ãƒ†ã‚¹ãƒˆã‚±ãƒ¼ã‚¹1:", result1)
+    
+    # ãƒ†ã‚¹ãƒˆã‚±ãƒ¼ã‚¹2: <think>ã‚¿ã‚°ãªã—
+    answer2 = "ã“ã‚Œã¯æ™®é€šã®å›ç­”ã§ã™ã€‚"
+    result2 = _parse_answer_with_think(answer2)
+    print("ãƒ†ã‚¹ãƒˆã‚±ãƒ¼ã‚¹2:", result2)
+    
+    # ãƒ†ã‚¹ãƒˆã‚±ãƒ¼ã‚¹3: å®Ÿéš›ã®Q&Aãƒšã‚¢ä¿å­˜ãƒ†ã‚¹ãƒˆ
+    qa_pairs = [
+        {
+            "question": "ãƒ†ã‚¹ãƒˆè³ªå•1",
+            "answer": "<think>ã“ã‚Œã¯æ€è€ƒãƒ—ãƒ­ã‚»ã‚¹ã§ã™</think>ã“ã‚Œã¯ãƒ†ã‚¹ãƒˆå›ç­”1ã§ã™ã€‚"
+        },
+        {
+            "question": "ãƒ†ã‚¹ãƒˆè³ªå•2", 
+            "answer": "ã“ã‚Œã¯æ™®é€šã®å›ç­”ã§ã™ã€‚"
+        }
+    ]
+    
+    test_dir = Path("test_output")
+    test_dir.mkdir(exist_ok=True)
+    
+    _save_qa_pairs_to_xml(qa_pairs, test_dir, "test_subelement.xml")
+    
+    # ç”Ÿæˆã•ã‚ŒãŸãƒ•ã‚¡ã‚¤ãƒ«ã‚’èª­ã‚“ã§ç¢ºèª
+    generated_file = test_dir / "test_subelement.xml"
+    if generated_file.exists():
+        content = generated_file.read_text(encoding='utf-8')
+        print("\nç”Ÿæˆã•ã‚ŒãŸXML:")
+        print(content)
+        
+        if "&lt;think&gt;" in content:
+            print("âŒ <think>ã‚¿ã‚°ãŒã‚¨ã‚¹ã‚±ãƒ¼ãƒ—ã•ã‚Œã¦ã„ã¾ã™!")
+        else:
+            print("âœ… <think>ã‚¿ã‚°ã¯ã‚¨ã‚¹ã‚±ãƒ¼ãƒ—ã•ã‚Œã¦ã„ã¾ã›ã‚“!")
+    
+    # ã‚¯ãƒªãƒ¼ãƒ³ã‚¢ãƒƒãƒ—
+    import shutil
+    if test_dir.exists():
+        shutil.rmtree(test_dir)
+
+if __name__ == "__main__":
+    test_parse_answer_with_think()
diff --git a/tests/test_think_tag_preservation.py b/tests/test_think_tag_preservation.py
new file mode 100644
index 0000000..7ada6b0
--- /dev/null
+++ b/tests/test_think_tag_preservation.py
@@ -0,0 +1,57 @@
+#!/usr/bin/env python3
+"""<think>ã‚¿ã‚°ã®ã‚¨ã‚¹ã‚±ãƒ¼ãƒ—ãƒ†ã‚¹ãƒˆ"""
+
+import sys
+import os
+
+# ãƒ—ãƒ­ã‚¸ã‚§ã‚¯ãƒˆã®ãƒ«ãƒ¼ãƒˆãƒ‡ã‚£ãƒ¬ã‚¯ãƒˆãƒªã‚’ãƒ‘ã‚¹ã«è¿½åŠ 
+sys.path.insert(0, os.path.dirname(os.path.abspath(__file__)))
+
+from easy_dataset_cli.qa_generator import _decode_xml_entities
+
+def test_think_tag_preservation():
+    """<think>ã‚¿ã‚°ãŒé©åˆ‡ã«ä¿æŒã•ã‚Œã‚‹ã“ã¨ã‚’ãƒ†ã‚¹ãƒˆ"""
+    
+    # ãƒ†ã‚¹ãƒˆã‚±ãƒ¼ã‚¹1: <think>ã‚¿ã‚°ã‚’å«ã‚€å›ç­”
+    test_text1 = """<think>ã“ã‚Œã¯ãƒŸãƒˆã‚³ãƒ³ãƒ‰ãƒªã‚¢ã®æ©Ÿèƒ½ã«ã¤ã„ã¦ã®æ€è€ƒãƒ—ãƒ­ã‚»ã‚¹ã§ã™ã€‚ç´°èƒã®ã‚¨ãƒãƒ«ã‚®ãƒ¼å·¥å ´ã¨ã—ã¦æ©Ÿèƒ½ã—ã¾ã™ã€‚</think>ãƒŸãƒˆã‚³ãƒ³ãƒ‰ãƒªã‚¢ã¯ç´°èƒã®ã‚¨ãƒãƒ«ã‚®ãƒ¼é€šè²¨ã§ã‚ã‚‹ATPã‚’ç”Ÿæˆã™ã‚‹é‡è¦ãªç´°èƒå°å™¨å®˜ã§ã™ã€‚"""
+    
+    result1 = _decode_xml_entities(test_text1)
+    print("ãƒ†ã‚¹ãƒˆã‚±ãƒ¼ã‚¹1:")
+    print(f"å…¥åŠ›: {test_text1}")
+    print(f"å‡ºåŠ›: {result1}")
+    print(f"<think>ã‚¿ã‚°ãŒä¿æŒã•ã‚Œã¦ã„ã‚‹ã‹: {'<think>' in result1 and '</think>' in result1}")
+    print()
+    
+    # ãƒ†ã‚¹ãƒˆã‚±ãƒ¼ã‚¹2: HTMLã‚¨ãƒ³ãƒ†ã‚£ãƒ†ã‚£ã‚’å«ã‚€æ–‡å­—åˆ—
+    test_text2 = """<think>ATPã®ç”Ÿæˆã«ã¤ã„ã¦è€ƒãˆã¦ã¿ã¾ã™ã€‚&lt;ATP&gt;ã¯é‡è¦ãªåˆ†å­ã§ã™ã€‚</think>ATPã¯ã‚¢ãƒ‡ãƒã‚·ãƒ³ä¸‰ãƒªãƒ³é…¸ï¼ˆadenosine triphosphateï¼‰ã§ã€ç´°èƒå†…ã§ã‚¨ãƒãƒ«ã‚®ãƒ¼è²¯è”µã¨è»¢é€ã®å½¹å‰²ã‚’æœãŸã—ã¾ã™ã€‚"""
+    
+    result2 = _decode_xml_entities(test_text2)
+    print("ãƒ†ã‚¹ãƒˆã‚±ãƒ¼ã‚¹2:")
+    print(f"å…¥åŠ›: {test_text2}")
+    print(f"å‡ºåŠ›: {result2}")
+    print(f"<think>ã‚¿ã‚°ãŒä¿æŒã•ã‚Œã¦ã„ã‚‹ã‹: {'<think>' in result2 and '</think>' in result2}")
+    print(f"HTMLã‚¨ãƒ³ãƒ†ã‚£ãƒ†ã‚£ãŒãƒ‡ã‚³ãƒ¼ãƒ‰ã•ã‚Œã¦ã„ã‚‹ã‹: {'<ATP>' in result2}")
+    print()
+    
+    # ãƒ†ã‚¹ãƒˆã‚±ãƒ¼ã‚¹3: è¤‡æ•°ã®<think>ã‚¿ã‚°
+    test_text3 = """<think>æœ€åˆã®æ€è€ƒãƒ—ãƒ­ã‚»ã‚¹</think>æœ€åˆã®å›ç­”<think>äºŒç•ªç›®ã®æ€è€ƒãƒ—ãƒ­ã‚»ã‚¹</think>è¿½åŠ ã®èª¬æ˜"""
+    
+    result3 = _decode_xml_entities(test_text3)
+    print("ãƒ†ã‚¹ãƒˆã‚±ãƒ¼ã‚¹3:")
+    print(f"å…¥åŠ›: {test_text3}")
+    print(f"å‡ºåŠ›: {result3}")
+    print(f"è¤‡æ•°ã®<think>ã‚¿ã‚°ãŒä¿æŒã•ã‚Œã¦ã„ã‚‹ã‹: {result3.count('<think>') == 2 and result3.count('</think>') == 2}")
+    print()
+    
+    # ãƒ†ã‚¹ãƒˆã‚±ãƒ¼ã‚¹4: <think>ã‚¿ã‚°ãªã—ã€HTMLã‚¨ãƒ³ãƒ†ã‚£ãƒ†ã‚£ã®ã¿
+    test_text4 = """ã“ã‚Œã¯&amp;æ™®é€šã®&lt;å›ç­”&gt;ã§ã™ã€‚"""
+    
+    result4 = _decode_xml_entities(test_text4)
+    print("ãƒ†ã‚¹ãƒˆã‚±ãƒ¼ã‚¹4:")
+    print(f"å…¥åŠ›: {test_text4}")
+    print(f"å‡ºåŠ›: {result4}")
+    print(f"HTMLã‚¨ãƒ³ãƒ†ã‚£ãƒ†ã‚£ãŒãƒ‡ã‚³ãƒ¼ãƒ‰ã•ã‚Œã¦ã„ã‚‹ã‹: {'&' in result4 and '<å›ç­”>' in result4}")
+    print()
+
+if __name__ == "__main__":
+    test_think_tag_preservation()
diff --git a/tests/test_xml_parsing.py b/tests/test_xml_parsing.py
new file mode 100644
index 0000000..7183a79
--- /dev/null
+++ b/tests/test_xml_parsing.py
@@ -0,0 +1,121 @@
+#!/usr/bin/env python3
+"""XMLãƒ‘ãƒ¼ã‚¹æ”¹å–„ã®ãƒ†ã‚¹ãƒˆã‚¹ã‚¯ãƒªãƒ—ãƒˆ"""
+
+import sys
+import os
+sys.path.append(os.path.join(os.path.dirname(__file__), 'easy_dataset_cli'))
+
+from easy_dataset_cli.qa_generator import _parse_qa_response, _clean_llm_response
+from pathlib import Path
+import json
+
+def test_xml_parsing():
+    """XMLãƒ‘ãƒ¼ã‚¹ã®ãƒ†ã‚¹ãƒˆ"""
+    
+    # ãƒ†ã‚¹ãƒˆã‚±ãƒ¼ã‚¹1: æ­£å¸¸ãªXML
+    test_xml_1 = '''<QAPairs>
+<Pair>
+<Question>ãƒ†ã‚¹ãƒˆè³ªå•1</Question>
+<Answer>ãƒ†ã‚¹ãƒˆå›ç­”1</Answer>
+</Pair>
+<Pair>
+<Question>ãƒ†ã‚¹ãƒˆè³ªå•2</Question>
+<Answer>ãƒ†ã‚¹ãƒˆå›ç­”2</Answer>
+</Pair>
+</QAPairs>'''
+    
+    # ãƒ†ã‚¹ãƒˆã‚±ãƒ¼ã‚¹2: ãƒãƒƒã‚¯ã‚¯ã‚©ãƒ¼ãƒˆä»˜ãã®XMLï¼ˆã‚¨ãƒ©ãƒ¼ã®åŸå› ï¼‰
+    test_xml_2 = '''\```xml
+<QAPairs>
+<Pair>
+<Question>æ±æ–¹åœ°éœŠæ®¿ã¯ã©ã‚“ãªã‚¸ãƒ£ãƒ³ãƒ«ã®ã‚²ãƒ¼ãƒ ã§ã™ã‹ï¼Ÿ</Question>
+<Answer>å¼¾å¹•ç³»ã‚·ãƒ¥ãƒ¼ãƒ†ã‚£ãƒ³ã‚°ã‚²ãƒ¼ãƒ ã§ã€æ¨ªã‚¹ã‚¯ãƒ­ãƒ¼ãƒ«ã®å¼¾å¹•ã‚’å›é¿ã—ãªãŒã‚‰æ•µã‚’å€’ã™ã‚¿ã‚¤ãƒ—ã§ã™ã€‚</Answer>
+</Pair>
+<Pair>
+<Question>ã“ã®ã‚²ãƒ¼ãƒ ã¯ã©ã®OSã§ãƒ—ãƒ¬ã‚¤ã§ãã¾ã™ã‹ï¼Ÿ</Question>
+<Answer>Windows 2000ã€XPã€Vistaä»¥é™ã®PCã§å‹•ä½œã—ã€2020å¹´ã«ã¯Steamç‰ˆã‚‚é…ä¿¡ã•ã‚Œã¦ã„ã¾ã™ã€‚</Answer>
+</Pair>
+<Pair>
+<Question>æœ€ä½å‹•ä½œç’°å¢ƒã¯ä½•ã§ã™ã‹ï¼Ÿ</Question>
+<Answer>CPUã¯1GHzä»¥ä¸Šã®Pentiumã€DirectX 9.0ä»¥ä¸Šã€ãƒ¡ãƒ¢ãƒª256â€¯MBã€HDDç©ºãå®¹é‡600â€¯MBãŒå¿…è¦ã§ã™ã€‚</Answer>
+</Pair>
+<Pair>
+<Question>ã‚¤ãƒ³ã‚¹ãƒˆãƒ¼ãƒ«æ‰‹é †ã¯ç°¡å˜ã§ã™ã‹ï¼Ÿ</Question>
+<Answer>Steamç‰ˆãªã‚‰ã‚¢ã‚«ã‚¦ãƒ³ãƒˆã«ãƒ­ã‚°ã‚¤ãƒ³ã—ã¦ã€Œè³¼å…¥ã€â†’ã€Œã‚¤ãƒ³ã‚¹ãƒˆãƒ¼ãƒ«ã€ãƒœã‚¿ãƒ³ã‚’æŠ¼ã™ã ã‘ã§è‡ªå‹•ã‚¤ãƒ³ã‚¹ãƒˆãƒ¼ãƒ«ã•ã‚Œã¾ã™ã€‚</Answer>
+</Pair>
+</QAPairs>
+\```'''
+    
+    # ãƒ†ã‚¹ãƒˆã‚±ãƒ¼ã‚¹3: <Pair>ã‚¿ã‚°ã®ã¿ã®XML
+    test_xml_3 = '''<Pair>
+<Question>Pairã‚¿ã‚°ã®ã¿ã®è³ªå•1</Question>
+<Answer>Pairã‚¿ã‚°ã®ã¿ã®å›ç­”1</Answer>
+</Pair>
+<Pair>
+<Question>Pairã‚¿ã‚°ã®ã¿ã®è³ªå•2</Question>
+<Answer>Pairã‚¿ã‚°ã®ã¿ã®å›ç­”2</Answer>
+</Pair>'''
+    
+    # ãƒ†ã‚¹ãƒˆã‚±ãƒ¼ã‚¹4: ä¸å®Œå…¨ãªXML
+    test_xml_4 = '''<QAPairs>
+<Pair>
+<Question>ä¸å®Œå…¨ãªXMLã®è³ªå•</Question>
+<Answer>ä¸å®Œå…¨ãªXMLã®å›ç­”</Answer>
+</Pair>
+<QAPairs>'''
+    
+    print("=== XMLãƒ‘ãƒ¼ã‚¹æ”¹å–„ãƒ†ã‚¹ãƒˆ ===\n")
+    
+    # ãƒ†ã‚¹ãƒˆã‚±ãƒ¼ã‚¹1
+    print("ãƒ†ã‚¹ãƒˆã‚±ãƒ¼ã‚¹1: æ­£å¸¸ãªXML")
+    result1 = _parse_qa_response(test_xml_1, None, None, None, None)
+    print(f"çµæœ: {len(result1)}ä»¶ã®Q&Aã‚’æŠ½å‡º")
+    for i, qa in enumerate(result1, 1):
+        print(f"  {i}. Q: {qa['question']}")
+        print(f"     A: {qa['answer']}")
+    print()
+    
+    # ãƒ†ã‚¹ãƒˆã‚±ãƒ¼ã‚¹2
+    print("ãƒ†ã‚¹ãƒˆã‚±ãƒ¼ã‚¹2: ãƒãƒƒã‚¯ã‚¯ã‚©ãƒ¼ãƒˆä»˜ãã®XMLï¼ˆå…ƒã®ã‚¨ãƒ©ãƒ¼ï¼‰")
+    result2 = _parse_qa_response(test_xml_2, None, None, None, None)
+    print(f"çµæœ: {len(result2)}ä»¶ã®Q&Aã‚’æŠ½å‡º")
+    for i, qa in enumerate(result2, 1):
+        print(f"  {i}. Q: {qa['question']}")
+        print(f"     A: {qa['answer']}")
+    print()
+    
+    # ãƒ†ã‚¹ãƒˆã‚±ãƒ¼ã‚¹3
+    print("ãƒ†ã‚¹ãƒˆã‚±ãƒ¼ã‚¹3: <Pair>ã‚¿ã‚°ã®ã¿ã®XML")
+    result3 = _parse_qa_response(test_xml_3, None, None, None, None)
+    print(f"çµæœ: {len(result3)}ä»¶ã®Q&Aã‚’æŠ½å‡º")
+    for i, qa in enumerate(result3, 1):
+        print(f"  {i}. Q: {qa['question']}")
+        print(f"     A: {qa['answer']}")
+    print()
+    
+    # ãƒ†ã‚¹ãƒˆã‚±ãƒ¼ã‚¹4
+    print("ãƒ†ã‚¹ãƒˆã‚±ãƒ¼ã‚¹4: ä¸å®Œå…¨ãªXML")
+    result4 = _parse_qa_response(test_xml_4, None, None, None, None)
+    print(f"çµæœ: {len(result4)}ä»¶ã®Q&Aã‚’æŠ½å‡º")
+    for i, qa in enumerate(result4, 1):
+        print(f"  {i}. Q: {qa['question']}")
+        print(f"     A: {qa['answer']}")
+    print()
+    
+    # ã‚¯ãƒªãƒ¼ãƒ‹ãƒ³ã‚°æ©Ÿèƒ½ã®ãƒ†ã‚¹ãƒˆ
+    print("=== ã‚¯ãƒªãƒ¼ãƒ‹ãƒ³ã‚°æ©Ÿèƒ½ãƒ†ã‚¹ãƒˆ ===")
+    cleaned = _clean_llm_response(test_xml_2)
+    print("ã‚¯ãƒªãƒ¼ãƒ‹ãƒ³ã‚°å‰:")
+    print(test_xml_2[:200] + "...")
+    print("\nã‚¯ãƒªãƒ¼ãƒ‹ãƒ³ã‚°å¾Œ:")
+    print(cleaned[:200] + "...")
+    
+    return len(result1) > 0 and len(result2) > 0 and len(result3) > 0
+
+if __name__ == "__main__":
+    success = test_xml_parsing()
+    if success:
+        print("\nâœ… ã™ã¹ã¦ã®ãƒ†ã‚¹ãƒˆãŒæˆåŠŸã—ã¾ã—ãŸï¼")
+    else:
+        print("\nâŒ ãƒ†ã‚¹ãƒˆã«å¤±æ•—ã—ã¾ã—ãŸã€‚")
+    sys.exit(0 if success else 1)
```
